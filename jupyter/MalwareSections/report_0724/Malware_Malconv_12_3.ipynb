{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# specify which GPU will be used\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pymysql\n",
    "from warnings import filterwarnings\n",
    "\n",
    "_connection = None\n",
    "\n",
    "def get_connection(db_config):\n",
    "    \"\"\"\n",
    "    get db connection\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global _connection\n",
    "    if _connection is None:\n",
    "        _connection = pymysql.connect(host=db_config['host'], user=db_config['username'],\n",
    "                                      password=db_config['password'],\n",
    "                                      db=db_config['db'], charset=\"utf8\")\n",
    "        filterwarnings('ignore', category=pymysql.Warning)\n",
    "\n",
    "    return _connection\n",
    "\n",
    "\n",
    "def close():\n",
    "    \"\"\"\n",
    "    close DB connection\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global _connection\n",
    "    if _connection is not None:\n",
    "        _connection.close()\n",
    "    _connection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = {\n",
    "    'host': '172.26.187.242',\n",
    "    'username': 'malware_r',\n",
    "    'password': 'GEg22v2O7jbfWhb3',\n",
    "    'db': 'malware'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fields\n",
    "\n",
    "- mw_file_suffix: file name after hash value\n",
    "- mw_file_prefix: directory\n",
    "- mw_em_f: features of ember, splitted by \";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# the base function which can query sql and return dict data\n",
    "def get_specific_data(table_suffix, sql=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    global _connection\n",
    "    if _connection is None:\n",
    "        raise Exception(\"please init db connect first\")\n",
    "\n",
    "    cursor = _connection.cursor()\n",
    "    cursor.execute(\"SET NAMES utf8mb4\")\n",
    "\n",
    "    ret = []\n",
    "        \n",
    "    cursor.execute(sql)\n",
    "\n",
    "    field_names = [i[0] for i in cursor.description]\n",
    "\n",
    "    for row in cursor:\n",
    "        temp = {}\n",
    "        for key in range(len(row)):\n",
    "            temp[field_names[key]] = row[key]\n",
    "        ret.append(temp)\n",
    "     \n",
    "    cursor.close()\n",
    "    # _connection.close()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 23.17503261566162 seconds ---\n",
      "--- 24.909729957580566 seconds ---\n",
      "--- 23.01578664779663 seconds ---\n",
      "--- 23.8974347114563 seconds ---\n",
      "--- 20.820040702819824 seconds ---\n",
      "--- 25.139378309249878 seconds ---\n",
      "--- 25.73338532447815 seconds ---\n",
      "--- 24.516175031661987 seconds ---\n",
      "--- 25.318306922912598 seconds ---\n",
      "--- 23.870152473449707 seconds ---\n",
      "--- 22.4960675239563 seconds ---\n",
      "--- 14.336087942123413 seconds ---\n",
      "--- 15.16492486000061 seconds ---\n",
      "--- 12.79147720336914 seconds ---\n",
      "--- 14.758151531219482 seconds ---\n",
      "--- 15.459365129470825 seconds ---\n",
      "268423\n"
     ]
    }
   ],
   "source": [
    "close()\n",
    "res1 = []\n",
    "get_connection(db)\n",
    "table_suffix = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "# Iterate all partitions of databases\n",
    "for suffix in table_suffix:\n",
    "    sql = \"\"\" \n",
    "select\n",
    "  a.mw_file_hash,\n",
    "  a.section_name,\n",
    "  c.mw_file_suffix as mw_file_size,\n",
    "  c.mw_file_prefix as mw_file_directory,\n",
    "  c.mw_num_engines,\n",
    "  a.pointerto_raw_data,\n",
    "  a.virtual_size,\n",
    "  d.mw_em_f\n",
    "from mw_index_2017_section_%s as a\n",
    "  inner join mw_index_2017_%s c on a.mw_file_hash = c.mw_file_hash\n",
    "  inner join mw_index_2017_feature_%s d on a.mw_file_hash = d.mw_file_hash\n",
    "where CNT_CODE = 1 and MEM_EXECUTE = 1 and c.mw_num_engines <> -1 and (c.mw_num_engines > 6 or c.mw_num_engines = 0) and\n",
    "      c.mw_file_prefix in ('201701', '201702')\n",
    "group by mw_file_hash\n",
    "    \"\"\" % (suffix, suffix, suffix)\n",
    "    res1.extend(get_specific_data(suffix, sql))\n",
    "close()\n",
    "print(len(res1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.196787118911743 seconds ---\n",
      "--- 8.897745370864868 seconds ---\n",
      "--- 7.0894858837127686 seconds ---\n",
      "--- 7.539840936660767 seconds ---\n",
      "--- 11.23170280456543 seconds ---\n",
      "--- 15.15299105644226 seconds ---\n",
      "--- 12.75526237487793 seconds ---\n",
      "--- 12.518447637557983 seconds ---\n",
      "--- 14.171578884124756 seconds ---\n",
      "--- 12.5701744556427 seconds ---\n",
      "--- 13.190277338027954 seconds ---\n",
      "--- 12.069642543792725 seconds ---\n",
      "--- 14.34741735458374 seconds ---\n",
      "--- 11.93936562538147 seconds ---\n",
      "--- 12.453815221786499 seconds ---\n",
      "--- 11.3638014793396 seconds ---\n",
      "154527\n"
     ]
    }
   ],
   "source": [
    "close()\n",
    "res2 = []\n",
    "get_connection(db)\n",
    "table_suffix = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "# Iterate all partitions of databases\n",
    "for suffix in table_suffix:\n",
    "    sql = \"\"\" \n",
    "select\n",
    "  a.mw_file_hash,\n",
    "  a.section_name,\n",
    "  c.mw_file_suffix as mw_file_size,\n",
    "  c.mw_file_prefix as mw_file_directory,\n",
    "  c.mw_num_engines,\n",
    "  a.pointerto_raw_data,\n",
    "  a.virtual_size,\n",
    "  d.mw_em_f\n",
    "from mw_index_2017_section_%s as a\n",
    "  inner join mw_index_2017_%s c on a.mw_file_hash = c.mw_file_hash\n",
    "  inner join mw_index_2017_feature_%s d on a.mw_file_hash = d.mw_file_hash\n",
    "where CNT_CODE = 1 and MEM_EXECUTE = 1 and c.mw_num_engines <> -1 and (c.mw_num_engines > 6 or c.mw_num_engines = 0) and\n",
    "      c.mw_file_prefix in ('201703')\n",
    "group by mw_file_hash\n",
    "    \"\"\" % (suffix, suffix, suffix)\n",
    "    res2.extend(get_specific_data(suffix, sql))\n",
    "close()\n",
    "print(len(res2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_length = 300000\n",
    "\n",
    "train_data = pd.DataFrame(res1)\n",
    "# train_data = train_data.loc[train_data.virtual_size <= max_length]\n",
    "# train_data = train_data.reset_index(drop=True)\n",
    "train_data.mw_num_engines[train_data.mw_num_engines == 0 ] = 0\n",
    "train_data.mw_num_engines[train_data.mw_num_engines > 6 ] = 1\n",
    "train_label = train_data.mw_num_engines.ravel()\n",
    "\n",
    "test_data = pd.DataFrame(res2)\n",
    "# test_data = test_data.loc[test_data.virtual_size <= max_length]\n",
    "# test_data = test_data.reset_index(drop=True)\n",
    "test_data.mw_num_engines[test_data.mw_num_engines == 0 ] = 0\n",
    "test_data.mw_num_engines[test_data.mw_num_engines > 6 ] = 1\n",
    "test_label = test_data.mw_num_engines.ravel()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data, train_label, test_size=0.1, random_state=2345)\n",
    "x_test = test_data\n",
    "y_test = test_label\n",
    "\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "x_val = x_val.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ember_feature(data):\n",
    "    ember_f = np.zeros((len(data.mw_em_f), 2351), dtype=float)\n",
    "    for index, item in data.iterrows():\n",
    "        ember_f[index, :] = item['mw_em_f'].split(';')\n",
    "    return ember_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_train, y_train, x_val, y_val):\n",
    "    params = {'application': 'binary'}\n",
    "    lgbm_dataset = lgb.Dataset(x_train, y_train.ravel())\n",
    "    valid_sets = lgb.Dataset(x_val, y_val.ravel())\n",
    "\n",
    "    model = lgb.train(params, lgbm_dataset, 100000, valid_sets=valid_sets, early_stopping_rounds=10)\n",
    "    y_pred = model.predict(x_val)\n",
    "    \n",
    "    loss = log_loss(y_val, y_pred)\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    acc = accuracy_score(y_val, (y_pred > 0.5).astype(int))\n",
    "#     model.save_model(file_path + \"-%04d-%.5f-%.5f.h5\" % (model.best_iteration, loss, acc),\n",
    "#                      num_iteration=model.best_iteration)\n",
    "    print(\"val loss : %.5f\" % loss)\n",
    "    print(\"auc score : %.5f\" % auc)\n",
    "    print(\"accuracy score : %.5f\" % acc)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_etrain = get_ember_feature(x_train)\n",
    "x_eval = get_ember_feature(x_val)\n",
    "x_etest = get_ember_feature(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.584837\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.525152\n",
      "[3]\tvalid_0's binary_logloss: 0.475066\n",
      "[4]\tvalid_0's binary_logloss: 0.434171\n",
      "[5]\tvalid_0's binary_logloss: 0.397788\n",
      "[6]\tvalid_0's binary_logloss: 0.367165\n",
      "[7]\tvalid_0's binary_logloss: 0.33936\n",
      "[8]\tvalid_0's binary_logloss: 0.314477\n",
      "[9]\tvalid_0's binary_logloss: 0.293052\n",
      "[10]\tvalid_0's binary_logloss: 0.274979\n",
      "[11]\tvalid_0's binary_logloss: 0.25826\n",
      "[12]\tvalid_0's binary_logloss: 0.243444\n",
      "[13]\tvalid_0's binary_logloss: 0.230319\n",
      "[14]\tvalid_0's binary_logloss: 0.218117\n",
      "[15]\tvalid_0's binary_logloss: 0.207164\n",
      "[16]\tvalid_0's binary_logloss: 0.196933\n",
      "[17]\tvalid_0's binary_logloss: 0.188156\n",
      "[18]\tvalid_0's binary_logloss: 0.180111\n",
      "[19]\tvalid_0's binary_logloss: 0.173023\n",
      "[20]\tvalid_0's binary_logloss: 0.166436\n",
      "[21]\tvalid_0's binary_logloss: 0.160319\n",
      "[22]\tvalid_0's binary_logloss: 0.154994\n",
      "[23]\tvalid_0's binary_logloss: 0.149537\n",
      "[24]\tvalid_0's binary_logloss: 0.144962\n",
      "[25]\tvalid_0's binary_logloss: 0.140252\n",
      "[26]\tvalid_0's binary_logloss: 0.136389\n",
      "[27]\tvalid_0's binary_logloss: 0.132668\n",
      "[28]\tvalid_0's binary_logloss: 0.129578\n",
      "[29]\tvalid_0's binary_logloss: 0.126473\n",
      "[30]\tvalid_0's binary_logloss: 0.123604\n",
      "[31]\tvalid_0's binary_logloss: 0.120843\n",
      "[32]\tvalid_0's binary_logloss: 0.118764\n",
      "[33]\tvalid_0's binary_logloss: 0.116353\n",
      "[34]\tvalid_0's binary_logloss: 0.11469\n",
      "[35]\tvalid_0's binary_logloss: 0.112789\n",
      "[36]\tvalid_0's binary_logloss: 0.110983\n",
      "[37]\tvalid_0's binary_logloss: 0.10925\n",
      "[38]\tvalid_0's binary_logloss: 0.107725\n",
      "[39]\tvalid_0's binary_logloss: 0.106381\n",
      "[40]\tvalid_0's binary_logloss: 0.105009\n",
      "[41]\tvalid_0's binary_logloss: 0.103885\n",
      "[42]\tvalid_0's binary_logloss: 0.102558\n",
      "[43]\tvalid_0's binary_logloss: 0.101303\n",
      "[44]\tvalid_0's binary_logloss: 0.100365\n",
      "[45]\tvalid_0's binary_logloss: 0.0994682\n",
      "[46]\tvalid_0's binary_logloss: 0.0982974\n",
      "[47]\tvalid_0's binary_logloss: 0.0973587\n",
      "[48]\tvalid_0's binary_logloss: 0.0966202\n",
      "[49]\tvalid_0's binary_logloss: 0.0956885\n",
      "[50]\tvalid_0's binary_logloss: 0.0950033\n",
      "[51]\tvalid_0's binary_logloss: 0.0942373\n",
      "[52]\tvalid_0's binary_logloss: 0.0934674\n",
      "[53]\tvalid_0's binary_logloss: 0.092784\n",
      "[54]\tvalid_0's binary_logloss: 0.0920939\n",
      "[55]\tvalid_0's binary_logloss: 0.0915333\n",
      "[56]\tvalid_0's binary_logloss: 0.0909727\n",
      "[57]\tvalid_0's binary_logloss: 0.0903101\n",
      "[58]\tvalid_0's binary_logloss: 0.0898569\n",
      "[59]\tvalid_0's binary_logloss: 0.089297\n",
      "[60]\tvalid_0's binary_logloss: 0.0888315\n",
      "[61]\tvalid_0's binary_logloss: 0.0883579\n",
      "[62]\tvalid_0's binary_logloss: 0.0878267\n",
      "[63]\tvalid_0's binary_logloss: 0.0874009\n",
      "[64]\tvalid_0's binary_logloss: 0.0869275\n",
      "[65]\tvalid_0's binary_logloss: 0.0864462\n",
      "[66]\tvalid_0's binary_logloss: 0.0861235\n",
      "[67]\tvalid_0's binary_logloss: 0.0856461\n",
      "[68]\tvalid_0's binary_logloss: 0.0850599\n",
      "[69]\tvalid_0's binary_logloss: 0.084766\n",
      "[70]\tvalid_0's binary_logloss: 0.0844219\n",
      "[71]\tvalid_0's binary_logloss: 0.0840976\n",
      "[72]\tvalid_0's binary_logloss: 0.0837751\n",
      "[73]\tvalid_0's binary_logloss: 0.0834962\n",
      "[74]\tvalid_0's binary_logloss: 0.0832389\n",
      "[75]\tvalid_0's binary_logloss: 0.0829585\n",
      "[76]\tvalid_0's binary_logloss: 0.0826804\n",
      "[77]\tvalid_0's binary_logloss: 0.0824321\n",
      "[78]\tvalid_0's binary_logloss: 0.0822343\n",
      "[79]\tvalid_0's binary_logloss: 0.0817971\n",
      "[80]\tvalid_0's binary_logloss: 0.0815945\n",
      "[81]\tvalid_0's binary_logloss: 0.081321\n",
      "[82]\tvalid_0's binary_logloss: 0.0809393\n",
      "[83]\tvalid_0's binary_logloss: 0.0807222\n",
      "[84]\tvalid_0's binary_logloss: 0.080471\n",
      "[85]\tvalid_0's binary_logloss: 0.0802467\n",
      "[86]\tvalid_0's binary_logloss: 0.0800229\n",
      "[87]\tvalid_0's binary_logloss: 0.0798014\n",
      "[88]\tvalid_0's binary_logloss: 0.0795935\n",
      "[89]\tvalid_0's binary_logloss: 0.0793572\n",
      "[90]\tvalid_0's binary_logloss: 0.0790134\n",
      "[91]\tvalid_0's binary_logloss: 0.0788035\n",
      "[92]\tvalid_0's binary_logloss: 0.0786459\n",
      "[93]\tvalid_0's binary_logloss: 0.0784716\n",
      "[94]\tvalid_0's binary_logloss: 0.0782972\n",
      "[95]\tvalid_0's binary_logloss: 0.07814\n",
      "[96]\tvalid_0's binary_logloss: 0.0778517\n",
      "[97]\tvalid_0's binary_logloss: 0.0775958\n",
      "[98]\tvalid_0's binary_logloss: 0.0774564\n",
      "[99]\tvalid_0's binary_logloss: 0.0772555\n",
      "[100]\tvalid_0's binary_logloss: 0.0771177\n",
      "[101]\tvalid_0's binary_logloss: 0.076898\n",
      "[102]\tvalid_0's binary_logloss: 0.0767769\n",
      "[103]\tvalid_0's binary_logloss: 0.0766625\n",
      "[104]\tvalid_0's binary_logloss: 0.0764442\n",
      "[105]\tvalid_0's binary_logloss: 0.0763594\n",
      "[106]\tvalid_0's binary_logloss: 0.0762152\n",
      "[107]\tvalid_0's binary_logloss: 0.0760422\n",
      "[108]\tvalid_0's binary_logloss: 0.0759352\n",
      "[109]\tvalid_0's binary_logloss: 0.0758216\n",
      "[110]\tvalid_0's binary_logloss: 0.0757788\n",
      "[111]\tvalid_0's binary_logloss: 0.0756899\n",
      "[112]\tvalid_0's binary_logloss: 0.0755715\n",
      "[113]\tvalid_0's binary_logloss: 0.0754003\n",
      "[114]\tvalid_0's binary_logloss: 0.0752646\n",
      "[115]\tvalid_0's binary_logloss: 0.0751457\n",
      "[116]\tvalid_0's binary_logloss: 0.0750298\n",
      "[117]\tvalid_0's binary_logloss: 0.0748873\n",
      "[118]\tvalid_0's binary_logloss: 0.0748318\n",
      "[119]\tvalid_0's binary_logloss: 0.0747085\n",
      "[120]\tvalid_0's binary_logloss: 0.0746167\n",
      "[121]\tvalid_0's binary_logloss: 0.0744849\n",
      "[122]\tvalid_0's binary_logloss: 0.0743745\n",
      "[123]\tvalid_0's binary_logloss: 0.0741773\n",
      "[124]\tvalid_0's binary_logloss: 0.0740383\n",
      "[125]\tvalid_0's binary_logloss: 0.0739164\n",
      "[126]\tvalid_0's binary_logloss: 0.0737946\n",
      "[127]\tvalid_0's binary_logloss: 0.0737258\n",
      "[128]\tvalid_0's binary_logloss: 0.0736222\n",
      "[129]\tvalid_0's binary_logloss: 0.0735315\n",
      "[130]\tvalid_0's binary_logloss: 0.0734798\n",
      "[131]\tvalid_0's binary_logloss: 0.0734276\n",
      "[132]\tvalid_0's binary_logloss: 0.0733521\n",
      "[133]\tvalid_0's binary_logloss: 0.0730704\n",
      "[134]\tvalid_0's binary_logloss: 0.0729558\n",
      "[135]\tvalid_0's binary_logloss: 0.0728168\n",
      "[136]\tvalid_0's binary_logloss: 0.0726855\n",
      "[137]\tvalid_0's binary_logloss: 0.0726625\n",
      "[138]\tvalid_0's binary_logloss: 0.0725736\n",
      "[139]\tvalid_0's binary_logloss: 0.0724354\n",
      "[140]\tvalid_0's binary_logloss: 0.0723957\n",
      "[141]\tvalid_0's binary_logloss: 0.0723259\n",
      "[142]\tvalid_0's binary_logloss: 0.0721851\n",
      "[143]\tvalid_0's binary_logloss: 0.0721443\n",
      "[144]\tvalid_0's binary_logloss: 0.0720655\n",
      "[145]\tvalid_0's binary_logloss: 0.0719314\n",
      "[146]\tvalid_0's binary_logloss: 0.0718651\n",
      "[147]\tvalid_0's binary_logloss: 0.0717277\n",
      "[148]\tvalid_0's binary_logloss: 0.0717164\n",
      "[149]\tvalid_0's binary_logloss: 0.0716585\n",
      "[150]\tvalid_0's binary_logloss: 0.0715785\n",
      "[151]\tvalid_0's binary_logloss: 0.0715211\n",
      "[152]\tvalid_0's binary_logloss: 0.071434\n",
      "[153]\tvalid_0's binary_logloss: 0.0714466\n",
      "[154]\tvalid_0's binary_logloss: 0.0713572\n",
      "[155]\tvalid_0's binary_logloss: 0.0712679\n",
      "[156]\tvalid_0's binary_logloss: 0.0712601\n",
      "[157]\tvalid_0's binary_logloss: 0.0712301\n",
      "[158]\tvalid_0's binary_logloss: 0.0711405\n",
      "[159]\tvalid_0's binary_logloss: 0.0710626\n",
      "[160]\tvalid_0's binary_logloss: 0.0710561\n",
      "[161]\tvalid_0's binary_logloss: 0.0709749\n",
      "[162]\tvalid_0's binary_logloss: 0.0709283\n",
      "[163]\tvalid_0's binary_logloss: 0.0708601\n",
      "[164]\tvalid_0's binary_logloss: 0.0707226\n",
      "[165]\tvalid_0's binary_logloss: 0.0707001\n",
      "[166]\tvalid_0's binary_logloss: 0.0705925\n",
      "[167]\tvalid_0's binary_logloss: 0.0705629\n",
      "[168]\tvalid_0's binary_logloss: 0.0704495\n",
      "[169]\tvalid_0's binary_logloss: 0.0704005\n",
      "[170]\tvalid_0's binary_logloss: 0.0703539\n",
      "[171]\tvalid_0's binary_logloss: 0.0703555\n",
      "[172]\tvalid_0's binary_logloss: 0.0703147\n",
      "[173]\tvalid_0's binary_logloss: 0.0702327\n",
      "[174]\tvalid_0's binary_logloss: 0.0701619\n",
      "[175]\tvalid_0's binary_logloss: 0.070183\n",
      "[176]\tvalid_0's binary_logloss: 0.0701981\n",
      "[177]\tvalid_0's binary_logloss: 0.0701707\n",
      "[178]\tvalid_0's binary_logloss: 0.07019\n",
      "[179]\tvalid_0's binary_logloss: 0.0700962\n",
      "[180]\tvalid_0's binary_logloss: 0.0700876\n",
      "[181]\tvalid_0's binary_logloss: 0.0700643\n",
      "[182]\tvalid_0's binary_logloss: 0.0699883\n",
      "[183]\tvalid_0's binary_logloss: 0.0699511\n",
      "[184]\tvalid_0's binary_logloss: 0.0698788\n",
      "[185]\tvalid_0's binary_logloss: 0.0698056\n",
      "[186]\tvalid_0's binary_logloss: 0.0697829\n",
      "[187]\tvalid_0's binary_logloss: 0.0697239\n",
      "[188]\tvalid_0's binary_logloss: 0.0696119\n",
      "[189]\tvalid_0's binary_logloss: 0.0695774\n",
      "[190]\tvalid_0's binary_logloss: 0.0695571\n",
      "[191]\tvalid_0's binary_logloss: 0.0695712\n",
      "[192]\tvalid_0's binary_logloss: 0.0695115\n",
      "[193]\tvalid_0's binary_logloss: 0.0694744\n",
      "[194]\tvalid_0's binary_logloss: 0.0693998\n",
      "[195]\tvalid_0's binary_logloss: 0.0693561\n",
      "[196]\tvalid_0's binary_logloss: 0.069343\n",
      "[197]\tvalid_0's binary_logloss: 0.0693006\n",
      "[198]\tvalid_0's binary_logloss: 0.0692604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199]\tvalid_0's binary_logloss: 0.0691758\n",
      "[200]\tvalid_0's binary_logloss: 0.0690944\n",
      "[201]\tvalid_0's binary_logloss: 0.0690698\n",
      "[202]\tvalid_0's binary_logloss: 0.06899\n",
      "[203]\tvalid_0's binary_logloss: 0.0689309\n",
      "[204]\tvalid_0's binary_logloss: 0.0688958\n",
      "[205]\tvalid_0's binary_logloss: 0.0688629\n",
      "[206]\tvalid_0's binary_logloss: 0.068872\n",
      "[207]\tvalid_0's binary_logloss: 0.0688608\n",
      "[208]\tvalid_0's binary_logloss: 0.0688034\n",
      "[209]\tvalid_0's binary_logloss: 0.0687467\n",
      "[210]\tvalid_0's binary_logloss: 0.0687248\n",
      "[211]\tvalid_0's binary_logloss: 0.0687062\n",
      "[212]\tvalid_0's binary_logloss: 0.0687077\n",
      "[213]\tvalid_0's binary_logloss: 0.0686773\n",
      "[214]\tvalid_0's binary_logloss: 0.0686425\n",
      "[215]\tvalid_0's binary_logloss: 0.0686317\n",
      "[216]\tvalid_0's binary_logloss: 0.0686314\n",
      "[217]\tvalid_0's binary_logloss: 0.0686491\n",
      "[218]\tvalid_0's binary_logloss: 0.0687027\n",
      "[219]\tvalid_0's binary_logloss: 0.0686796\n",
      "[220]\tvalid_0's binary_logloss: 0.0686566\n",
      "[221]\tvalid_0's binary_logloss: 0.0686633\n",
      "[222]\tvalid_0's binary_logloss: 0.0686472\n",
      "[223]\tvalid_0's binary_logloss: 0.0685945\n",
      "[224]\tvalid_0's binary_logloss: 0.0685198\n",
      "[225]\tvalid_0's binary_logloss: 0.0685299\n",
      "[226]\tvalid_0's binary_logloss: 0.0684537\n",
      "[227]\tvalid_0's binary_logloss: 0.0684227\n",
      "[228]\tvalid_0's binary_logloss: 0.0683725\n",
      "[229]\tvalid_0's binary_logloss: 0.0683349\n",
      "[230]\tvalid_0's binary_logloss: 0.068288\n",
      "[231]\tvalid_0's binary_logloss: 0.0682974\n",
      "[232]\tvalid_0's binary_logloss: 0.0682875\n",
      "[233]\tvalid_0's binary_logloss: 0.0682518\n",
      "[234]\tvalid_0's binary_logloss: 0.0682328\n",
      "[235]\tvalid_0's binary_logloss: 0.0682351\n",
      "[236]\tvalid_0's binary_logloss: 0.0681761\n",
      "[237]\tvalid_0's binary_logloss: 0.0680402\n",
      "[238]\tvalid_0's binary_logloss: 0.0680035\n",
      "[239]\tvalid_0's binary_logloss: 0.0679187\n",
      "[240]\tvalid_0's binary_logloss: 0.0679216\n",
      "[241]\tvalid_0's binary_logloss: 0.0678994\n",
      "[242]\tvalid_0's binary_logloss: 0.0678645\n",
      "[243]\tvalid_0's binary_logloss: 0.0678678\n",
      "[244]\tvalid_0's binary_logloss: 0.0678243\n",
      "[245]\tvalid_0's binary_logloss: 0.0677368\n",
      "[246]\tvalid_0's binary_logloss: 0.0677345\n",
      "[247]\tvalid_0's binary_logloss: 0.0677092\n",
      "[248]\tvalid_0's binary_logloss: 0.0676841\n",
      "[249]\tvalid_0's binary_logloss: 0.0676478\n",
      "[250]\tvalid_0's binary_logloss: 0.0675943\n",
      "[251]\tvalid_0's binary_logloss: 0.0676157\n",
      "[252]\tvalid_0's binary_logloss: 0.0675708\n",
      "[253]\tvalid_0's binary_logloss: 0.0675387\n",
      "[254]\tvalid_0's binary_logloss: 0.0675608\n",
      "[255]\tvalid_0's binary_logloss: 0.0675549\n",
      "[256]\tvalid_0's binary_logloss: 0.067525\n",
      "[257]\tvalid_0's binary_logloss: 0.067501\n",
      "[258]\tvalid_0's binary_logloss: 0.0674241\n",
      "[259]\tvalid_0's binary_logloss: 0.0674022\n",
      "[260]\tvalid_0's binary_logloss: 0.067403\n",
      "[261]\tvalid_0's binary_logloss: 0.0673263\n",
      "[262]\tvalid_0's binary_logloss: 0.0673302\n",
      "[263]\tvalid_0's binary_logloss: 0.0673314\n",
      "[264]\tvalid_0's binary_logloss: 0.067299\n",
      "[265]\tvalid_0's binary_logloss: 0.0672639\n",
      "[266]\tvalid_0's binary_logloss: 0.0672726\n",
      "[267]\tvalid_0's binary_logloss: 0.0672551\n",
      "[268]\tvalid_0's binary_logloss: 0.0672211\n",
      "[269]\tvalid_0's binary_logloss: 0.0672099\n",
      "[270]\tvalid_0's binary_logloss: 0.0672155\n",
      "[271]\tvalid_0's binary_logloss: 0.0672189\n",
      "[272]\tvalid_0's binary_logloss: 0.0671965\n",
      "[273]\tvalid_0's binary_logloss: 0.0671822\n",
      "[274]\tvalid_0's binary_logloss: 0.0671562\n",
      "[275]\tvalid_0's binary_logloss: 0.0671688\n",
      "[276]\tvalid_0's binary_logloss: 0.0670955\n",
      "[277]\tvalid_0's binary_logloss: 0.067074\n",
      "[278]\tvalid_0's binary_logloss: 0.067037\n",
      "[279]\tvalid_0's binary_logloss: 0.0670226\n",
      "[280]\tvalid_0's binary_logloss: 0.0670143\n",
      "[281]\tvalid_0's binary_logloss: 0.0669954\n",
      "[282]\tvalid_0's binary_logloss: 0.0669771\n",
      "[283]\tvalid_0's binary_logloss: 0.0669482\n",
      "[284]\tvalid_0's binary_logloss: 0.0669221\n",
      "[285]\tvalid_0's binary_logloss: 0.0668923\n",
      "[286]\tvalid_0's binary_logloss: 0.0668545\n",
      "[287]\tvalid_0's binary_logloss: 0.0668341\n",
      "[288]\tvalid_0's binary_logloss: 0.0668113\n",
      "[289]\tvalid_0's binary_logloss: 0.0668031\n",
      "[290]\tvalid_0's binary_logloss: 0.0667735\n",
      "[291]\tvalid_0's binary_logloss: 0.0667375\n",
      "[292]\tvalid_0's binary_logloss: 0.0666723\n",
      "[293]\tvalid_0's binary_logloss: 0.0666527\n",
      "[294]\tvalid_0's binary_logloss: 0.0668429\n",
      "[295]\tvalid_0's binary_logloss: 0.06683\n",
      "[296]\tvalid_0's binary_logloss: 0.0667804\n",
      "[297]\tvalid_0's binary_logloss: 0.0667344\n",
      "[298]\tvalid_0's binary_logloss: 0.0666573\n",
      "[299]\tvalid_0's binary_logloss: 0.0665649\n",
      "[300]\tvalid_0's binary_logloss: 0.0665739\n",
      "[301]\tvalid_0's binary_logloss: 0.0665583\n",
      "[302]\tvalid_0's binary_logloss: 0.0665525\n",
      "[303]\tvalid_0's binary_logloss: 0.0664965\n",
      "[304]\tvalid_0's binary_logloss: 0.0664701\n",
      "[305]\tvalid_0's binary_logloss: 0.0664684\n",
      "[306]\tvalid_0's binary_logloss: 0.0664535\n",
      "[307]\tvalid_0's binary_logloss: 0.0664704\n",
      "[308]\tvalid_0's binary_logloss: 0.0664523\n",
      "[309]\tvalid_0's binary_logloss: 0.0664541\n",
      "[310]\tvalid_0's binary_logloss: 0.0664238\n",
      "[311]\tvalid_0's binary_logloss: 0.0665051\n",
      "[312]\tvalid_0's binary_logloss: 0.0665229\n",
      "[313]\tvalid_0's binary_logloss: 0.0665059\n",
      "[314]\tvalid_0's binary_logloss: 0.0664831\n",
      "[315]\tvalid_0's binary_logloss: 0.0664549\n",
      "[316]\tvalid_0's binary_logloss: 0.0664424\n",
      "[317]\tvalid_0's binary_logloss: 0.0663939\n",
      "[318]\tvalid_0's binary_logloss: 0.0663879\n",
      "[319]\tvalid_0's binary_logloss: 0.0663855\n",
      "[320]\tvalid_0's binary_logloss: 0.0663699\n",
      "[321]\tvalid_0's binary_logloss: 0.0663734\n",
      "[322]\tvalid_0's binary_logloss: 0.0663836\n",
      "[323]\tvalid_0's binary_logloss: 0.0663739\n",
      "[324]\tvalid_0's binary_logloss: 0.0663495\n",
      "[325]\tvalid_0's binary_logloss: 0.0663087\n",
      "[326]\tvalid_0's binary_logloss: 0.0663128\n",
      "[327]\tvalid_0's binary_logloss: 0.0663061\n",
      "[328]\tvalid_0's binary_logloss: 0.0662875\n",
      "[329]\tvalid_0's binary_logloss: 0.0662699\n",
      "[330]\tvalid_0's binary_logloss: 0.0662582\n",
      "[331]\tvalid_0's binary_logloss: 0.0662465\n",
      "[332]\tvalid_0's binary_logloss: 0.0662344\n",
      "[333]\tvalid_0's binary_logloss: 0.0662612\n",
      "[334]\tvalid_0's binary_logloss: 0.0662352\n",
      "[335]\tvalid_0's binary_logloss: 0.0662024\n",
      "[336]\tvalid_0's binary_logloss: 0.066209\n",
      "[337]\tvalid_0's binary_logloss: 0.0662232\n",
      "[338]\tvalid_0's binary_logloss: 0.0661812\n",
      "[339]\tvalid_0's binary_logloss: 0.066148\n",
      "[340]\tvalid_0's binary_logloss: 0.0661195\n",
      "[341]\tvalid_0's binary_logloss: 0.0661174\n",
      "[342]\tvalid_0's binary_logloss: 0.0661071\n",
      "[343]\tvalid_0's binary_logloss: 0.0660785\n",
      "[344]\tvalid_0's binary_logloss: 0.0660601\n",
      "[345]\tvalid_0's binary_logloss: 0.066031\n",
      "[346]\tvalid_0's binary_logloss: 0.0660213\n",
      "[347]\tvalid_0's binary_logloss: 0.0660043\n",
      "[348]\tvalid_0's binary_logloss: 0.0659791\n",
      "[349]\tvalid_0's binary_logloss: 0.0659652\n",
      "[350]\tvalid_0's binary_logloss: 0.0659342\n",
      "[351]\tvalid_0's binary_logloss: 0.0658956\n",
      "[352]\tvalid_0's binary_logloss: 0.0658357\n",
      "[353]\tvalid_0's binary_logloss: 0.0658148\n",
      "[354]\tvalid_0's binary_logloss: 0.0657978\n",
      "[355]\tvalid_0's binary_logloss: 0.0657717\n",
      "[356]\tvalid_0's binary_logloss: 0.0657496\n",
      "[357]\tvalid_0's binary_logloss: 0.0657381\n",
      "[358]\tvalid_0's binary_logloss: 0.0657603\n",
      "[359]\tvalid_0's binary_logloss: 0.0657353\n",
      "[360]\tvalid_0's binary_logloss: 0.0657223\n",
      "[361]\tvalid_0's binary_logloss: 0.0656999\n",
      "[362]\tvalid_0's binary_logloss: 0.0656959\n",
      "[363]\tvalid_0's binary_logloss: 0.0656734\n",
      "[364]\tvalid_0's binary_logloss: 0.0656986\n",
      "[365]\tvalid_0's binary_logloss: 0.0656929\n",
      "[366]\tvalid_0's binary_logloss: 0.0657094\n",
      "[367]\tvalid_0's binary_logloss: 0.0657288\n",
      "[368]\tvalid_0's binary_logloss: 0.0657042\n",
      "[369]\tvalid_0's binary_logloss: 0.065711\n",
      "[370]\tvalid_0's binary_logloss: 0.0657065\n",
      "[371]\tvalid_0's binary_logloss: 0.0657071\n",
      "[372]\tvalid_0's binary_logloss: 0.0657316\n",
      "[373]\tvalid_0's binary_logloss: 0.0657246\n",
      "Early stopping, best iteration is:\n",
      "[363]\tvalid_0's binary_logloss: 0.0656734\n",
      "val loss : 0.06567\n",
      "auc score : 0.99449\n",
      "accuracy score : 0.98193\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model = get_model(x_etrain, y_train, x_eval, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_model(y_pred, test_y):\n",
    "    \n",
    "    loss = log_loss(test_y, y_pred)\n",
    "    auc = roc_auc_score(test_y, y_pred)\n",
    "    acc = accuracy_score(test_y, (y_pred > 0.5).astype(int))\n",
    "    print(\"loss : %.5f\" % loss)\n",
    "    print(\"auc score : %.5f\" % auc)\n",
    "    print(\"accuracy score : %.5f\" % acc)\n",
    "\n",
    "    fp_np_index = np.where(test_y == 0)\n",
    "    fp_np = y_pred[fp_np_index].shape[0]\n",
    "    thre_index = int(np.ceil(fp_np - fp_np * 0.001))\n",
    "\n",
    "    sorted_pred_prob = np.sort(y_pred[fp_np_index], axis=0)\n",
    "    thre = sorted_pred_prob[thre_index]\n",
    "    if thre == 1:\n",
    "        thre = max(sorted_pred_prob[np.where(sorted_pred_prob != 1)])\n",
    "\n",
    "    y_pred_prob = np.vstack((y_pred.transpose(), (1 - y_pred).transpose())).transpose()\n",
    "    y_pred_prob[:, 1] = thre\n",
    "    y_pred_label = np.argmin(y_pred_prob, axis=-1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_y, y_pred_label).ravel()\n",
    "    fp_rate = fp / (fp + tn)\n",
    "    recall_rate = tp / (tp + fn)\n",
    "\n",
    "    print(\"thre: %.10f\"%  thre)\n",
    "    print(\"fp:  %.10f\"%  fp_rate)\n",
    "    print(\"recall:  %.10f\"%  recall_rate)\n",
    "    \n",
    "    return auc, loss, recall_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.25842\n",
      "auc score : 0.95684\n",
      "accuracy score : 0.92796\n",
      "thre: 0.9969162514\n",
      "fp:  0.0009850342\n",
      "recall:  0.1083908575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9568397385651055, 0.2584200520476898, 0.1083908574934806)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = model.predict(x_etest)\n",
    "y_pred_e = np.zeros((len(y_p), 1))\n",
    "for i in range(len(y_p)):\n",
    "    y_pred_e[i, 0] = y_p[i]\n",
    "\n",
    "estimate_model(y_pred_e, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, list_IDs, datasets, labels, batch_size=32, dim=8192, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.datasets = datasets\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, self.dim), dtype=float)\n",
    "        y = np.zeros(self.batch_size, dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            base_path = \"/ssd/2017/{0}/{1}{2}\"\n",
    "            item = self.datasets.loc[ID]\n",
    "            file_path = base_path.format(item[\"mw_file_directory\"], item[\"mw_file_hash\"], item[\"mw_file_size\"])\n",
    "            in_file = open(file_path, 'rb')\n",
    "            in_file.seek(item['pointerto_raw_data'])\n",
    "            if item['virtual_size'] > max_length:\n",
    "                bytes_data = [int(single_byte) for single_byte in in_file.read(max_length)]\n",
    "            else:\n",
    "                bytes_data = [int(single_byte) for single_byte in in_file.read(item['virtual_size'])]\n",
    "            X[i, 0:len(bytes_data)] = bytes_data\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras import Input\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Dense, Embedding, Conv1D, Multiply, GlobalMaxPooling1D, Dropout\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TMalConv(object):\n",
    "    \"\"\"\n",
    "    train of mal conv\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.max_len = max_length\n",
    "        self.history = None\n",
    "        self.model = None\n",
    "        self.p_md5 = None\n",
    "        self.time = time.time()\n",
    "        self.summary = {\n",
    "            'time':time.time(),\n",
    "            'batch_size': 32,\n",
    "            'epochs': 64,\n",
    "            'g_c_filter': 128,\n",
    "            'g_c_kernel_size': 500,\n",
    "            'g_c_stride': 500,\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        \n",
    "    def get_p(self, key):\n",
    "        \"\"\"\n",
    "        get the parameter from the summary\n",
    "        :param key:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.summary[key]\n",
    "\n",
    "    def gate_cnn(self, gate_cnn_input):\n",
    "        \"\"\"\n",
    "        construct a gated cnn by the specific kernel size\n",
    "        :param gate_cnn_input:\n",
    "        :param kernel_size:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        conv1_out = Conv1D(self.get_p(\"g_c_filter\"), self.get_p(\"g_c_kernel_size\"), strides=self.get_p(\"g_c_stride\"))(\n",
    "            gate_cnn_input)\n",
    "        conv2_out = Conv1D(self.get_p(\"g_c_filter\"), self.get_p(\"g_c_kernel_size\"), strides=self.get_p(\"g_c_stride\"),\n",
    "                           activation=\"sigmoid\")(gate_cnn_input)\n",
    "        merged = Multiply()([conv1_out, conv2_out])\n",
    "        gate_cnn_output = GlobalMaxPooling1D()(merged)\n",
    "        return gate_cnn_output\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        get a model\n",
    "        :param max_len:\n",
    "        :param kernel_sizes:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        net_input = Input(shape=(self.max_len,))\n",
    "\n",
    "        embedding_out = Embedding(256, 8, input_length=self.max_len)(net_input)\n",
    "        merged = self.gate_cnn(embedding_out)\n",
    "\n",
    "        dense_out = Dense(128)(merged)\n",
    "        \n",
    "        net_output = Dense(1, activation='sigmoid')(dense_out)\n",
    "\n",
    "        model = keras.models.Model(inputs=net_input, outputs=net_output)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        batch_size = self.get_p(\"batch_size\")\n",
    "        epochs = self.get_p(\"epochs\")\n",
    "\n",
    "        self.model = self.get_model()\n",
    "\n",
    "        print('Length of the train: ', len(x_train))\n",
    "        print('Length of the validation: ', len(x_val))\n",
    "        \n",
    "#         tensor_board = TensorBoard(log_dir='./logs/', batch_size=batch_size)\n",
    "        file_path = \"/home/zhaoqi/BaseTrain/models/\"+ str(self.time) +\"-{epoch:04d}-{val_loss:.5f}-{val_acc:.5f}.h5\"\n",
    "        early_stopping = EarlyStopping(\"val_loss\", patience=3, verbose=0, mode='auto')\n",
    "        check_point = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "        callbacks_list = [check_point, early_stopping]\n",
    "\n",
    "        # Generators\n",
    "        training_generator = DataGenerator(range(len(x_train)), x_train, y_train, batch_size, self.max_len)\n",
    "        validation_generator = DataGenerator(range(len(x_val)), x_val, y_val, batch_size, self.max_len)\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "        self.model.fit_generator(generator=training_generator,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 use_multiprocessing=True,\n",
    "                                 epochs=epochs,\n",
    "                                 workers=6,\n",
    "                                 callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train:  241580\n",
      "Length of the validation:  26843\n",
      "Epoch 1/64\n",
      "7549/7549 [==============================] - 7011s 929ms/step - loss: 0.1698 - acc: 0.9464 - val_loss: 0.1518 - val_acc: 0.9534\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15181, saving model to /home/zhaoqi/BaseTrain/models/1532328550.5178833-0001-0.15181-0.95342.h5\n",
      "Epoch 2/64\n",
      "7549/7549 [==============================] - 6100s 808ms/step - loss: 0.1228 - acc: 0.9622 - val_loss: 0.1467 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15181 to 0.14671, saving model to /home/zhaoqi/BaseTrain/models/1532328550.5178833-0002-0.14671-0.95551.h5\n",
      "Epoch 3/64\n",
      "7549/7549 [==============================] - 6040s 800ms/step - loss: 0.0957 - acc: 0.9729 - val_loss: 0.1433 - val_acc: 0.9568\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14671 to 0.14332, saving model to /home/zhaoqi/BaseTrain/models/1532328550.5178833-0003-0.14332-0.95678.h5\n",
      "Epoch 4/64\n",
      " 287/7549 [>.............................] - ETA: 1:16:28 - loss: 0.0798 - acc: 0.9797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-38:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-33:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-39:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 29, in __getitem__\n",
      "    X, y = self.__data_generation(list_IDs_temp)\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 29, in __getitem__\n",
      "    X, y = self.__data_generation(list_IDs_temp)\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 50, in __data_generation\n",
      "    in_file = open(file_path, 'rb')\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 51, in __data_generation\n",
      "    in_file.seek(item['pointerto_raw_data'])\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 29, in __getitem__\n",
      "    X, y = self.__data_generation(list_IDs_temp)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 29, in __getitem__\n",
      "    X, y = self.__data_generation(list_IDs_temp)\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 50, in __data_generation\n",
      "    in_file = open(file_path, 'rb')\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 50, in __data_generation\n",
      "    in_file = open(file_path, 'rb')\n",
      "KeyboardInterrupt\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 29, in __getitem__\n",
      "    X, y = self.__data_generation(list_IDs_temp)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-15-16e7f329ed3a>\", line 51, in __data_generation\n",
      "    in_file.seek(item['pointerto_raw_data'])\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-42acf2777b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTMalConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-5a50f379a01d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-5a50f379a01d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                                  \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                                  callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t_instance = TMalConv()\n",
    "t_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/home/zhaoqi/BaseTrain/models/'\n",
    "f_name = '1532328550.5178833-0003-0.14332-0.95678.h5'\n",
    "c_model = load_model(model_dir + f_name)\n",
    "\n",
    "# test_generator = DataGenerator(range(len(x_test)), x_test, y_test, 32, max_length, False)\n",
    "# y_pred = c_model.predict_generator(generator=test_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.33252\n",
      "auc score : 0.94611\n",
      "accuracy score : 0.89069\n",
      "thre: 0.9984807372\n",
      "fp:  0.0002911013\n",
      "recall:  0.0323258668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9461135205276512, 0.3325151933146175, 0.03232586683031605)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_model(y_pred, y_test[0:len(y_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Malconv and Ember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7549/7549 [==============================] - 5044s 668ms/step\n",
      "838/838 [==============================] - 478s 571ms/step\n",
      "4828/4828 [==============================] - 2550s 528ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model_f = Model(c_model.input, c_model.layers[-2].output)\n",
    "\n",
    "train_generator = DataGenerator(range(len(x_train)), x_train, y_train, 32, max_length, False)\n",
    "malcon_train_x = model_f.predict_generator(generator=train_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)\n",
    "\n",
    "val_generator = DataGenerator(range(len(x_val)), x_val, y_val, 32, max_length, False)\n",
    "malcon_val_x = model_f.predict_generator(generator=val_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)\n",
    "\n",
    "test_generator = DataGenerator(range(len(x_test)), x_test, y_test, 32, max_length, False)\n",
    "malcon_test_x = model_f.predict_generator(generator=test_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_feature(m_data, e_data):\n",
    "    num = len(m_data)\n",
    "    m_x = np.zeros((num, 128+2351), dtype=float)\n",
    "    \n",
    "    for index in range(num):\n",
    "        m_x[index, 0:128] = m_data[index]\n",
    "        m_x[index, 128:128+2351] = e_data[index]  \n",
    "    return m_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.573842\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.505857\n",
      "[3]\tvalid_0's binary_logloss: 0.450531\n",
      "[4]\tvalid_0's binary_logloss: 0.404264\n",
      "[5]\tvalid_0's binary_logloss: 0.36538\n",
      "[6]\tvalid_0's binary_logloss: 0.332398\n",
      "[7]\tvalid_0's binary_logloss: 0.304012\n",
      "[8]\tvalid_0's binary_logloss: 0.279572\n",
      "[9]\tvalid_0's binary_logloss: 0.258307\n",
      "[10]\tvalid_0's binary_logloss: 0.239977\n",
      "[11]\tvalid_0's binary_logloss: 0.223902\n",
      "[12]\tvalid_0's binary_logloss: 0.209692\n",
      "[13]\tvalid_0's binary_logloss: 0.197407\n",
      "[14]\tvalid_0's binary_logloss: 0.186504\n",
      "[15]\tvalid_0's binary_logloss: 0.177078\n",
      "[16]\tvalid_0's binary_logloss: 0.168876\n",
      "[17]\tvalid_0's binary_logloss: 0.161752\n",
      "[18]\tvalid_0's binary_logloss: 0.155464\n",
      "[19]\tvalid_0's binary_logloss: 0.149885\n",
      "[20]\tvalid_0's binary_logloss: 0.144831\n",
      "[21]\tvalid_0's binary_logloss: 0.140344\n",
      "[22]\tvalid_0's binary_logloss: 0.136735\n",
      "[23]\tvalid_0's binary_logloss: 0.133351\n",
      "[24]\tvalid_0's binary_logloss: 0.130235\n",
      "[25]\tvalid_0's binary_logloss: 0.127569\n",
      "[26]\tvalid_0's binary_logloss: 0.125354\n",
      "[27]\tvalid_0's binary_logloss: 0.123617\n",
      "[28]\tvalid_0's binary_logloss: 0.12187\n",
      "[29]\tvalid_0's binary_logloss: 0.120458\n",
      "[30]\tvalid_0's binary_logloss: 0.11909\n",
      "[31]\tvalid_0's binary_logloss: 0.1178\n",
      "[32]\tvalid_0's binary_logloss: 0.116752\n",
      "[33]\tvalid_0's binary_logloss: 0.115895\n",
      "[34]\tvalid_0's binary_logloss: 0.11518\n",
      "[35]\tvalid_0's binary_logloss: 0.114536\n",
      "[36]\tvalid_0's binary_logloss: 0.113852\n",
      "[37]\tvalid_0's binary_logloss: 0.113095\n",
      "[38]\tvalid_0's binary_logloss: 0.112621\n",
      "[39]\tvalid_0's binary_logloss: 0.112223\n",
      "[40]\tvalid_0's binary_logloss: 0.111952\n",
      "[41]\tvalid_0's binary_logloss: 0.111524\n",
      "[42]\tvalid_0's binary_logloss: 0.111387\n",
      "[43]\tvalid_0's binary_logloss: 0.111048\n",
      "[44]\tvalid_0's binary_logloss: 0.110708\n",
      "[45]\tvalid_0's binary_logloss: 0.110541\n",
      "[46]\tvalid_0's binary_logloss: 0.110723\n",
      "[47]\tvalid_0's binary_logloss: 0.110784\n",
      "[48]\tvalid_0's binary_logloss: 0.110826\n",
      "[49]\tvalid_0's binary_logloss: 0.110824\n",
      "[50]\tvalid_0's binary_logloss: 0.110605\n",
      "[51]\tvalid_0's binary_logloss: 0.110543\n",
      "[52]\tvalid_0's binary_logloss: 0.110454\n",
      "[53]\tvalid_0's binary_logloss: 0.110446\n",
      "[54]\tvalid_0's binary_logloss: 0.110429\n",
      "[55]\tvalid_0's binary_logloss: 0.110053\n",
      "[56]\tvalid_0's binary_logloss: 0.110131\n",
      "[57]\tvalid_0's binary_logloss: 0.109878\n",
      "[58]\tvalid_0's binary_logloss: 0.109932\n",
      "[59]\tvalid_0's binary_logloss: 0.109682\n",
      "[60]\tvalid_0's binary_logloss: 0.109615\n",
      "[61]\tvalid_0's binary_logloss: 0.109629\n",
      "[62]\tvalid_0's binary_logloss: 0.10931\n",
      "[63]\tvalid_0's binary_logloss: 0.109262\n",
      "[64]\tvalid_0's binary_logloss: 0.109206\n",
      "[65]\tvalid_0's binary_logloss: 0.109154\n",
      "[66]\tvalid_0's binary_logloss: 0.109016\n",
      "[67]\tvalid_0's binary_logloss: 0.108827\n",
      "[68]\tvalid_0's binary_logloss: 0.108655\n",
      "[69]\tvalid_0's binary_logloss: 0.108607\n",
      "[70]\tvalid_0's binary_logloss: 0.108449\n",
      "[71]\tvalid_0's binary_logloss: 0.108491\n",
      "[72]\tvalid_0's binary_logloss: 0.108449\n",
      "[73]\tvalid_0's binary_logloss: 0.108617\n",
      "[74]\tvalid_0's binary_logloss: 0.108564\n",
      "[75]\tvalid_0's binary_logloss: 0.108559\n",
      "[76]\tvalid_0's binary_logloss: 0.108815\n",
      "[77]\tvalid_0's binary_logloss: 0.108676\n",
      "[78]\tvalid_0's binary_logloss: 0.108634\n",
      "[79]\tvalid_0's binary_logloss: 0.108683\n",
      "[80]\tvalid_0's binary_logloss: 0.108784\n",
      "[81]\tvalid_0's binary_logloss: 0.108709\n",
      "[82]\tvalid_0's binary_logloss: 0.108909\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.108449\n",
      "val loss : 0.10845\n",
      "auc score : 0.99133\n",
      "accuracy score : 0.96920\n"
     ]
    }
   ],
   "source": [
    "merge_train_x = merge_feature(malcon_train_x, x_etrain)\n",
    "merge_val_x = merge_feature(malcon_val_x, x_eval)\n",
    "merge_test_x = merge_feature(malcon_test_x, x_etest)\n",
    "\n",
    "model_m = get_model(merge_train_x, y_train[0:len(merge_train_x)], merge_val_x, y_val[0:len(merge_val_x)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.34086\n",
      "auc score : 0.95414\n",
      "accuracy score : 0.90378\n",
      "thre: 0.9939017798\n",
      "fp:  0.0008509114\n",
      "recall:  0.1281067812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9541435176854167, 0.340863601189653, 0.1281067812212335)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = model_m.predict(merge_test_x)\n",
    "y_pred = np.zeros((len(y_p), 1))\n",
    "for i in range(len(y_p)):\n",
    "    y_pred[i, 0] = y_p[i]\n",
    "\n",
    "estimate_model(y_pred, y_test[0:len(merge_test_x)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
