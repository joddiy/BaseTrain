{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# specify which GPU will be used\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import os\n",
    "\n",
    "import pymysql\n",
    "from warnings import filterwarnings\n",
    "\n",
    "_connection = None\n",
    "\n",
    "def get_connection(db_config):\n",
    "    \"\"\"\n",
    "    get db connection\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global _connection\n",
    "    if _connection is None:\n",
    "        _connection = pymysql.connect(host=db_config['host'], user=db_config['username'],\n",
    "                                      password=db_config['password'],\n",
    "                                      db=db_config['db'], charset=\"utf8\")\n",
    "        filterwarnings('ignore', category=pymysql.Warning)\n",
    "\n",
    "    return _connection\n",
    "\n",
    "\n",
    "def close():\n",
    "    \"\"\"\n",
    "    close DB connection\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global _connection\n",
    "    if _connection is not None:\n",
    "        _connection.close()\n",
    "    _connection = None\n",
    "    \n",
    "db = {\n",
    "    'host': '172.26.187.242',\n",
    "    'username': 'malware_r',\n",
    "    'password': 'GEg22v2O7jbfWhb3',\n",
    "    'db': 'malware'\n",
    "}\n",
    "\n",
    "import time\n",
    "\n",
    "# the base function which can query sql and return dict data\n",
    "def get_specific_data(table_suffix, sql=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    global _connection\n",
    "    if _connection is None:\n",
    "        raise Exception(\"please init db connect first\")\n",
    "\n",
    "    cursor = _connection.cursor()\n",
    "    cursor.execute(\"SET NAMES utf8mb4\")\n",
    "\n",
    "    ret = []\n",
    "        \n",
    "    cursor.execute(sql)\n",
    "\n",
    "    field_names = [i[0] for i in cursor.description]\n",
    "\n",
    "    for row in cursor:\n",
    "        temp = {}\n",
    "        for key in range(len(row)):\n",
    "            temp[field_names[key]] = row[key]\n",
    "        ret.append(temp)\n",
    "     \n",
    "    cursor.close()\n",
    "    # _connection.close()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.1742422580719 seconds ---\n",
      "5899\n"
     ]
    }
   ],
   "source": [
    "close()\n",
    "res1 = []\n",
    "get_connection(db)\n",
    "table_suffix = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "table_suffix = [\"0\"]\n",
    "# Iterate all partitions of databases\n",
    "for suffix in table_suffix:\n",
    "    sql = \"\"\" \n",
    "select\n",
    "  a.mw_file_hash,\n",
    "  a.section_name,\n",
    "  b.mw_file_suffix as mw_file_size,\n",
    "  b.mw_file_prefix as mw_file_directory,\n",
    "  b.mw_num_engines,\n",
    "  a.pointerto_raw_data,\n",
    "  a.virtual_size,\n",
    "  d.mw_em_f\n",
    "from (\n",
    "       select\n",
    "         mw_file_hash,\n",
    "         section_name,\n",
    "         pointerto_raw_data,\n",
    "         virtual_size,\n",
    "         count(1) as cnt\n",
    "       from mw_index_2017_section_%s\n",
    "       where CNT_CODE = 1 and MEM_EXECUTE = 1\n",
    "       group by mw_file_hash) a\n",
    "  inner join mw_index_2017_%s b on a.mw_file_hash = b.mw_file_hash and a.cnt = 1 and b.mw_num_engines <> -1 and\n",
    "                                  (b.mw_num_engines >= 4 or b.mw_num_engines = 0) and\n",
    "                                  b.mw_file_prefix in ('201704')\n",
    "  inner join mw_index_2017_feature_%s d on a.mw_file_hash = d.mw_file_hash\n",
    "    \"\"\" % (suffix, suffix, suffix)\n",
    "    res1.extend(get_specific_data(suffix, sql))\n",
    "close()\n",
    "print(len(res1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.925442695617676 seconds ---\n",
      "945\n"
     ]
    }
   ],
   "source": [
    "close()\n",
    "res2 = []\n",
    "get_connection(db)\n",
    "table_suffix = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "table_suffix = [\"0\"]\n",
    "# Iterate all partitions of databases\n",
    "for suffix in table_suffix:\n",
    "    sql = \"\"\" \n",
    "select\n",
    "  a.mw_file_hash,\n",
    "  a.section_name,\n",
    "  b.mw_file_suffix as mw_file_size,\n",
    "  b.mw_file_prefix as mw_file_directory,\n",
    "  b.mw_num_engines,\n",
    "  a.pointerto_raw_data,\n",
    "  a.virtual_size,\n",
    "  d.mw_em_f\n",
    "from (\n",
    "       select\n",
    "         mw_file_hash,\n",
    "         section_name,\n",
    "         pointerto_raw_data,\n",
    "         virtual_size,\n",
    "         count(1) as cnt\n",
    "       from mw_index_2017_section_%s\n",
    "       where CNT_CODE = 1 and MEM_EXECUTE = 1\n",
    "       group by mw_file_hash) a\n",
    "  inner join mw_index_2017_%s b on a.mw_file_hash = b.mw_file_hash and a.cnt = 1 and b.mw_num_engines <> -1 and\n",
    "                                  (b.mw_num_engines >= 4 or b.mw_num_engines = 0) and a.virtual_size < 10240 and\n",
    "                                  b.mw_file_prefix in ('201705')\n",
    "  inner join mw_index_2017_feature_%s d on a.mw_file_hash = d.mw_file_hash\n",
    "    \"\"\" % (suffix, suffix, suffix)\n",
    "    res2.extend(get_specific_data(suffix, sql))\n",
    "close()\n",
    "print(len(res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_length = 10240\n",
    "\n",
    "train_data = pd.DataFrame(res1)\n",
    "# train_data = train_data.loc[train_data.virtual_size <= max_length]\n",
    "# train_data = train_data.reset_index(drop=True)\n",
    "train_data.mw_num_engines[train_data.mw_num_engines == 0 ] = 0\n",
    "train_data.mw_num_engines[train_data.mw_num_engines >= 4 ] = 1\n",
    "train_label = train_data.mw_num_engines.ravel()\n",
    "\n",
    "test_data = pd.DataFrame(res2)\n",
    "# test_data = test_data.loc[test_data.virtual_size <= max_length]\n",
    "# test_data = test_data.reset_index(drop=True)\n",
    "test_data.mw_num_engines[test_data.mw_num_engines == 0 ] = 0\n",
    "test_data.mw_num_engines[test_data.mw_num_engines >= 4 ] = 1\n",
    "test_label = test_data.mw_num_engines.ravel()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data, train_label, test_size=0.1, random_state=2345)\n",
    "x_test = test_data\n",
    "y_test = test_label\n",
    "\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "x_val = x_val.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, list_IDs, datasets, labels, batch_size=32, dim=8192, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.datasets = datasets\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        np.random.seed(5432)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, self.dim), dtype=float)\n",
    "        y = np.zeros(self.batch_size, dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            base_path = \"/ssd/2017/{0}/{1}{2}\"\n",
    "            item = self.datasets.loc[ID]\n",
    "            file_path = base_path.format(item[\"mw_file_directory\"], item[\"mw_file_hash\"], item[\"mw_file_size\"])\n",
    "            in_file = open(file_path, 'rb')\n",
    "            in_file.seek(item['pointerto_raw_data'])\n",
    "            if item['virtual_size'] > max_length:\n",
    "                bytes_data = [int(single_byte) for single_byte in in_file.read(max_length)]\n",
    "            else:\n",
    "                bytes_data = [int(single_byte) for single_byte in in_file.read(item['virtual_size'])]\n",
    "            X[i, 0:len(bytes_data)] = bytes_data\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:57: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 10240)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 10240, 8)     1024        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 10240, 8)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 10240, 32)    65568       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 10240, 32)    65568       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 10240, 32)    0           conv1d_19[0][0]                  \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 10240, 32)    0           multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 10240, 32)    262176      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 10240, 32)    262176      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 10240, 32)    0           conv1d_21[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_9 (Maximum)             (None, 10240, 32)    0           multiply_11[0][0]                \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 10240, 32)    0           maximum_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 10240, 32)    131104      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 10240, 32)    131104      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 10240, 32)    0           conv1d_23[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_10 (Maximum)            (None, 10240, 32)    0           multiply_12[0][0]                \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 10240, 32)    0           maximum_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 10240, 32)    87072       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 10240, 32)    87072       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 10240, 32)    0           conv1d_25[0][0]                  \n",
      "                                                                 conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_11 (Maximum)            (None, 10240, 32)    0           multiply_13[0][0]                \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 10240, 32)    0           maximum_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 10240, 32)    65568       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 10240, 32)    65568       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 10240, 32)    0           conv1d_27[0][0]                  \n",
      "                                                                 conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_12 (Maximum)            (None, 10240, 32)    0           multiply_14[0][0]                \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 10240, 32)    0           maximum_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 10240, 32)    52256       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 10240, 32)    52256       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 10240, 32)    0           conv1d_29[0][0]                  \n",
      "                                                                 conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_13 (Maximum)            (None, 10240, 32)    0           multiply_15[0][0]                \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 10240, 32)    0           maximum_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 10240, 32)    43040       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 10240, 32)    43040       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 10240, 32)    0           conv1d_31[0][0]                  \n",
      "                                                                 conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_14 (Maximum)            (None, 10240, 32)    0           multiply_16[0][0]                \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 10240, 32)    0           maximum_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 10240, 32)    36896       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 10240, 32)    36896       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 10240, 32)    0           conv1d_33[0][0]                  \n",
      "                                                                 conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_15 (Maximum)            (None, 10240, 32)    0           multiply_17[0][0]                \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 10240, 32)    0           maximum_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 10240, 32)    32800       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 10240, 32)    32800       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 10240, 32)    0           conv1d_35[0][0]                  \n",
      "                                                                 conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_16 (Maximum)            (None, 10240, 32)    0           multiply_18[0][0]                \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           maximum_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          global_max_pooling1d_2[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,554,017\n",
      "Trainable params: 1,554,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train:  5309\n",
      "Length of the validation:  590\n",
      "Epoch 1/64\n",
      "331/331 [==============================] - 118s 355ms/step - loss: 0.4652 - acc: 0.7672 - val_loss: 0.4132 - val_acc: 0.8212\n",
      "\n",
      "Epoch 00001: saving model to /home/zhaoqi/BaseTrain/models/1533013817.1850631-0001-0.41321-0.82118.h5\n",
      "Epoch 2/64\n",
      "331/331 [==============================] - 114s 344ms/step - loss: 0.3569 - acc: 0.8454 - val_loss: 0.4495 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00002: saving model to /home/zhaoqi/BaseTrain/models/1533013817.1850631-0002-0.44948-0.81597.h5\n",
      "Epoch 3/64\n",
      "  3/331 [..............................] - ETA: 1:49 - loss: 0.2046 - acc: 0.9375"
     ]
    }
   ],
   "source": [
    "# import hashlib\n",
    "import json\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras import Input\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Dense, Embedding, Conv1D, Multiply, GlobalMaxPooling1D, concatenate, Dropout, Maximum, Flatten, Activation\n",
    "from keras.models import load_model\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "max_len = max_length\n",
    "time = time.time()\n",
    "\n",
    "summary = {\n",
    "    'batch_size': 16,\n",
    "    'epochs': 64,\n",
    "}\n",
    "\n",
    "def get_p(key):\n",
    "    return summary[key]\n",
    "\n",
    "def res_dilated_block_1(filters, dilation_rate, filter_size):\n",
    "    def layer(input_):\n",
    "        \n",
    "        input_ = Activation('relu')(input_)\n",
    "        conv_1 = Conv1D(filters, filter_size, padding='same')(input_)\n",
    "        conv_2 = Conv1D(filters, filter_size, dilation_rate=dilation_rate, padding='causal',\n",
    "                        activation='sigmoid')(input_)\n",
    "        \n",
    "        merged = Multiply()([conv_1, conv_2])\n",
    "        if dilation_rate > 1:\n",
    "            out = Maximum()([merged, input_])\n",
    "        else:\n",
    "            out = merged\n",
    "        return out, conv_1\n",
    "    return layer\n",
    "\n",
    "def get_model(max_features):\n",
    "\n",
    "    input = Input(shape=(max_len,))\n",
    "    seq = Embedding(128, 8, input_length=max_len)(input)\n",
    "    res_layers = []\n",
    "    for i in range(9):\n",
    "        seq, curr_layer = res_dilated_block_1(32, 2**i, 256//i if i > 0 else 256)(seq)\n",
    "        res_layers.append(curr_layer)\n",
    "    \n",
    "    seq = GlobalMaxPooling1D()(seq)\n",
    "    seq = Dense(1, activation='sigmoid')(seq)\n",
    "    model = Model(input=input, output=seq)\n",
    "\n",
    "    model.summary()\n",
    "    from keras.utils.vis_utils import plot_model\n",
    "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    batch_size = get_p(\"batch_size\")\n",
    "    epochs = get_p(\"epochs\")\n",
    "\n",
    "    model = get_model(1024)\n",
    "\n",
    "    print('Length of the train: ', len(x_train))\n",
    "    print('Length of the validation: ', len(x_val))\n",
    "\n",
    "    #         tensor_board = TensorBoard(log_dir='./logs/', batch_size=batch_size)\n",
    "    file_path = \"/home/zhaoqi/BaseTrain/models/\"+ str(time) +\"-{epoch:04d}-{val_loss:.5f}-{val_acc:.5f}.h5\"\n",
    "    early_stopping = EarlyStopping(\"val_loss\", patience=3, verbose=0, mode='auto')\n",
    "    check_point = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=False, mode='auto')\n",
    "    callbacks_list = [check_point, early_stopping]\n",
    "\n",
    "    # Generators\n",
    "    training_generator = DataGenerator(range(len(x_train)), x_train, y_train, batch_size, max_len)\n",
    "    validation_generator = DataGenerator(range(len(x_val)), x_val, y_val, batch_size, max_len)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])\n",
    "    \n",
    "    model.fit_generator(generator=training_generator,\n",
    "                             validation_data=validation_generator,\n",
    "                             use_multiprocessing=True,\n",
    "                             epochs=epochs,\n",
    "                             workers=6,\n",
    "                             callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904/904 [==============================] - 88s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/home/zhaoqi/BaseTrain/models/'\n",
    "f_name = '1532956752.1549792-0005-0.10709-0.96727.h5'\n",
    "c_model = load_model(model_dir + f_name)\n",
    "\n",
    "test_generator = DataGenerator(range(len(x_test)), x_test, y_test, batch_size, max_length, False)\n",
    "y_pred = model.predict_generator(generator=test_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, confusion_matrix\n",
    "\n",
    "def estimate_model(y_pred, test_y):\n",
    "    \n",
    "    loss = log_loss(test_y, y_pred)\n",
    "    auc = roc_auc_score(test_y, y_pred)\n",
    "    acc = accuracy_score(test_y, (y_pred > 0.5).astype(int))\n",
    "    print(\"loss : %.5f\" % loss)\n",
    "    print(\"auc score : %.5f\" % auc)\n",
    "    print(\"accuracy score : %.5f\" % acc)\n",
    "\n",
    "    fp_np_index = np.where(test_y == 0)\n",
    "    fp_np = y_pred[fp_np_index].shape[0]\n",
    "    thre_index = int(np.ceil(fp_np - fp_np * 0.001))\n",
    "\n",
    "    sorted_pred_prob = np.sort(y_pred[fp_np_index], axis=0)\n",
    "    thre = sorted_pred_prob[thre_index]\n",
    "    if thre == 1:\n",
    "        thre = max(sorted_pred_prob[np.where(sorted_pred_prob != 1)])\n",
    "\n",
    "    y_pred_prob = np.vstack((y_pred.transpose(), (1 - y_pred).transpose())).transpose()\n",
    "    y_pred_prob[:, 1] = thre\n",
    "    y_pred_label = np.argmin(y_pred_prob, axis=-1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_y, y_pred_label).ravel()\n",
    "    fp_rate = fp / (fp + tn)\n",
    "    recall_rate = tp / (tp + fn)\n",
    "\n",
    "    print(\"thre: %.10f\"%  thre)\n",
    "    print(\"fp:  %.10f\"%  fp_rate)\n",
    "    print(\"recall:  %.10f\"%  recall_rate)\n",
    "    \n",
    "    return auc, loss, recall_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : nan\n",
      "auc score : 0.90337\n",
      "accuracy score : 0.86634\n",
      "thre: 0.9999341965\n",
      "fp:  0.0009204148\n",
      "recall:  0.4297299155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9033727002444281, nan, 0.42972991546972716)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_model(y_pred, y_test[0:len(y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : nan\n",
      "auc score : 0.90337\n",
      "accuracy score : 0.86634\n",
      "thre: 0.9999341965\n",
      "fp:  0.0009204148\n",
      "recall:  0.4297299155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9033727002444281, nan, 0.42972991546972716)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_model(y_pred, y_test[0:len(y_pred)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
