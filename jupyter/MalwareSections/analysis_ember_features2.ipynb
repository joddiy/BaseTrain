{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 2048\n",
    "\n",
    "def crop_exceed_data(data):\n",
    "    if len(data) <= max_len:\n",
    "        return data\n",
    "    return data[0: max_len]\n",
    "\n",
    "\n",
    "def get_bytes_array(data):\n",
    "    \"\"\"\n",
    "    int to bytes array\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bytes_data = bytes(map(int, data.split(\",\")))\n",
    "    bytes_data = crop_exceed_data(bytes_data)\n",
    "    return [int(single_byte) for single_byte in bytes_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 2048\n",
    "\n",
    "\n",
    "def crop_exceed_data(data):\n",
    "    if len(data) <= max_len:\n",
    "        return data\n",
    "    return data[0: max_len]\n",
    "\n",
    "\n",
    "def get_bytes_array(data):\n",
    "    \"\"\"\n",
    "    int to bytes array\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bytes_data = bytes(map(int, data.split(\",\")))\n",
    "    bytes_data = crop_exceed_data(bytes_data)\n",
    "    return [int(single_byte) for single_byte in bytes_data]\n",
    "\n",
    "\n",
    "def reverse_bytes(original):\n",
    "    \"\"\"\n",
    "    make the bytes inverse\n",
    "    :param original:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return original[::-1]\n",
    "\n",
    "\n",
    "def convert_int(str_bytes):\n",
    "    \"\"\"\n",
    "    convert bytes to int\n",
    "    :param str_bytes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return int.from_bytes(str_bytes, byteorder='big', signed=False)\n",
    "\n",
    "\n",
    "def decode_rich_sign(rich_sign):\n",
    "    \"\"\"\n",
    "    decode the rich sign, use the last 4 bytes to xor each 4 bytes from the start to end\n",
    "    :param rich_sign:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    key = rich_sign[-4:]\n",
    "    rich_sign_d = bytearray()\n",
    "    for i in range(len(rich_sign)):\n",
    "        rich_sign_d.append(rich_sign[i] ^ key[i % 4])\n",
    "    return bytes(rich_sign_d)\n",
    "\n",
    "\n",
    "def get_fixed_head(data):\n",
    "    \"\"\"\n",
    "    select some useful parts from the whole PE head\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bytes_data = bytes(map(int, data.split(\",\")))\n",
    "    # mz head\n",
    "    mz_head = bytes_data[0:64]\n",
    "    # # dos sub\n",
    "    ms_dos_sub = bytes_data[64:128]\n",
    "    # decode rich sign\n",
    "    rich_sign_end = bytes_data[128:].find(b'\\x52\\x69\\x63\\x68') + 136\n",
    "    rich_sign = decode_rich_sign(bytes_data[128:rich_sign_end])\n",
    "    # pe head\n",
    "    pe_head_start = bytes_data[128:].find(b'\\x50\\x45\\x00\\x00') + 128\n",
    "    pe_head = bytes_data[pe_head_start: pe_head_start + 24]\n",
    "    # there are two types of image optional head, PE 32 and PE 32+\n",
    "    other_head = bytes_data[pe_head_start + 24:]\n",
    "    if other_head[0:2] == b'\\x0b\\x01':\n",
    "        image_optional_head_end = 96\n",
    "    else:\n",
    "        image_optional_head_end = 112\n",
    "    image_optional_head = other_head[0:image_optional_head_end]\n",
    "    # data directory\n",
    "    data_directory = other_head[image_optional_head_end: image_optional_head_end + 128]\n",
    "    # append all above parts\n",
    "    fixed_head = mz_head + ms_dos_sub + rich_sign + pe_head + image_optional_head + data_directory\n",
    "    # fixed_head = mz_head + rich_sign + pe_head + image_optional_head + data_directory\n",
    "    # for each sections, just get the non-zero value\n",
    "    number_of_sections = convert_int(reverse_bytes(pe_head[6:8]))\n",
    "    for offset in range(number_of_sections):\n",
    "        offset_sections_start = image_optional_head_end + 128 + 40 * offset\n",
    "        fixed_head += other_head[offset_sections_start: offset_sections_start + 28] + \\\n",
    "                       other_head[offset_sections_start + 36:offset_sections_start + 40]\n",
    "        fixed_head += other_head[offset_sections_start + 36:offset_sections_start + 40]\n",
    "    return [int(single_byte) for single_byte in fixed_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train_x data:  (113133, 2048)\n",
      "Shape of the train_y data:  (113133, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x = pd.read_csv(\"./input/1_train.csv\", header=None, sep=\"|\", names=['row_data'], error_bad_lines=False)\n",
    "tmp_v = train_x[\"row_data\"].apply(lambda x: get_bytes_array(x))\n",
    "train_x = pd.DataFrame(tmp_v.tolist(), dtype=float)\n",
    "train_y = pd.read_csv(\"./input/1_train_label.csv\", header=None, error_bad_lines=False)\n",
    "del tmp_v\n",
    "print('Shape of the train_x data: ', train_x.shape)\n",
    "print('Shape of the train_y data: ', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the test_x data:  (143180, 2048)\n",
      "Shape of the test_y data:  (143180, 1)\n"
     ]
    }
   ],
   "source": [
    "test_x = pd.read_csv(\"./input/test.csv\", header=None, sep=\"|\", names=['row_data'], error_bad_lines=False)\n",
    "tmp_v = test_x[\"row_data\"].apply(lambda x: get_bytes_array(x))\n",
    "test_x = pd.DataFrame(tmp_v.tolist(), dtype=float)\n",
    "test_y = pd.read_csv(\"./input/test_label.csv\", header=None, error_bad_lines=False)\n",
    "del tmp_v\n",
    "print('Shape of the test_x data: ', test_x.shape)\n",
    "print('Shape of the test_y data: ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train_x data:  (113133, 2048)\n",
      "Shape of the train_y data:  (113133, 1)\n"
     ]
    }
   ],
   "source": [
    "tmp_v = pd.read_csv(\"./input/1_train.csv\", header=None, sep=\"|\", names=['row_data'], error_bad_lines=False)\n",
    "train_x = np.zeros((tmp_v.shape[0], max_len), dtype=int)\n",
    "train_y = pd.read_csv(\"./input/1_train_label.csv\", header=None, error_bad_lines=False)\n",
    "\n",
    "for i, item in enumerate(tmp_v[\"row_data\"]):\n",
    "    # Store sample\n",
    "    bytes_data = get_fixed_head(item)\n",
    "    if len(bytes_data) > max_len:\n",
    "        train_x[i, :] = bytes_data[:max_len]\n",
    "    else:\n",
    "        train_x[i, 0:len(bytes_data)] = bytes_data\n",
    "        \n",
    "del tmp_v       \n",
    "print('Shape of the train_x data: ', train_x.shape)\n",
    "print('Shape of the train_y data: ', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the test_x data:  (143180, 2048)\n",
      "Shape of the test_y data:  (143180, 1)\n"
     ]
    }
   ],
   "source": [
    "tmp_v = pd.read_csv(\"./input/test.csv\", header=None, sep=\"|\", names=['row_data'], error_bad_lines=False)\n",
    "test_x = np.zeros((tmp_v.shape[0], max_len), dtype=int)\n",
    "test_y = pd.read_csv(\"./input/test_label.csv\", header=None, error_bad_lines=False)\n",
    "\n",
    "for i, item in enumerate(tmp_v[\"row_data\"]):\n",
    "    # Store sample\n",
    "    bytes_data = get_fixed_head(item)\n",
    "    if len(bytes_data) > max_len:\n",
    "        test_x[i, :] = bytes_data[:max_len]\n",
    "    else:\n",
    "        test_x[i, 0:len(bytes_data)] = bytes_data\n",
    "        \n",
    "del tmp_v       \n",
    "print('Shape of the test_x data: ', test_x.shape)\n",
    "print('Shape of the test_y data: ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(data, label):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.05, random_state=5242)\n",
    "    params = {'application': 'binary'}\n",
    "    lgbm_dataset = lgb.Dataset(x_train, y_train.values.ravel())\n",
    "    valid_sets = lgb.Dataset(x_test, y_test.values.ravel())\n",
    "\n",
    "    model = lgb.train(params, lgbm_dataset, 100000, valid_sets=valid_sets, early_stopping_rounds=10, \n",
    "                     verbose_eval=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9320bda23d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Plot feature importances...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gain'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_model(train_x, train_y)\n",
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(model, max_num_features=21, figsize=(10, 10), importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_model(model, test_x, test_y):\n",
    "\n",
    "    y_p = model.predict(test_x)\n",
    "    y_pred = np.zeros((len(y_p), 1))\n",
    "    for i in range(len(y_p)):\n",
    "        y_pred[i, 0] = y_p[i]\n",
    "\n",
    "    loss = log_loss(test_y, y_pred)\n",
    "    auc = roc_auc_score(test_y, y_pred)\n",
    "    acc = accuracy_score(test_y, (y_pred > 0.5).astype(int))\n",
    "    print(\"loss : %.5f\" % loss)\n",
    "    print(\"auc score : %.5f\" % auc)\n",
    "    print(\"accuracy score : %.5f\" % acc)\n",
    "\n",
    "    fp_np_index = np.where(test_y == 0)\n",
    "    fp_np = y_pred[fp_np_index].shape[0]\n",
    "    thre_index = int(np.ceil(fp_np - fp_np * 0.001))\n",
    "\n",
    "    sorted_pred_prob = np.sort(y_pred[fp_np_index], axis=0)\n",
    "    thre = sorted_pred_prob[thre_index]\n",
    "    if thre == 1:\n",
    "        thre = max(sorted_pred_prob[np.where(sorted_pred_prob != 1)])\n",
    "\n",
    "    y_pred_prob = np.vstack((y_pred.transpose(), (1 - y_pred).transpose())).transpose()\n",
    "    y_pred_prob[:, 1] = thre\n",
    "    y_pred_label = np.argmin(y_pred_prob, axis=-1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_y, y_pred_label).ravel()\n",
    "    fp_rate = fp / (fp + tn)\n",
    "    recall_rate = tp / (tp + fn)\n",
    "\n",
    "    print(\"thre: %.5f\"%  thre)\n",
    "    print(\"fp:  %.5f\"%  fp_rate)\n",
    "    print(\"recall:  %.5f\"%  recall_rate)\n",
    "    \n",
    "    return auc, loss, recall_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc, loss, recall = estimate_model(model, test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
