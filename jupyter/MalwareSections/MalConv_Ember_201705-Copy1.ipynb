{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read index from mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pymysql\n",
    "from warnings import filterwarnings\n",
    "\n",
    "_connection = None\n",
    "\n",
    "def get_connection(db_config):\n",
    "    \"\"\"\n",
    "    get db connection\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global _connection\n",
    "    if _connection is None:\n",
    "        _connection = pymysql.connect(host=db_config['host'], user=db_config['username'],\n",
    "                                      password=db_config['password'],\n",
    "                                      db=db_config['db'], charset=\"utf8\")\n",
    "        filterwarnings('ignore', category=pymysql.Warning)\n",
    "\n",
    "    return _connection\n",
    "\n",
    "\n",
    "def close():\n",
    "    \"\"\"\n",
    "    close DB connection\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global _connection\n",
    "    if _connection is not None:\n",
    "        _connection.close()\n",
    "    _connection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = {\n",
    "    'host': '172.26.187.242',\n",
    "    'username': 'malware_r',\n",
    "    'password': 'GEg22v2O7jbfWhb3',\n",
    "    'db': 'malware'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_specific_data(table_suffix):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    global _connection\n",
    "    if _connection is None:\n",
    "        raise Exception(\"please init db connect first\")\n",
    "\n",
    "    cursor = _connection.cursor()\n",
    "    cursor.execute(\"SET NAMES utf8mb4\")\n",
    "\n",
    "    ret = []\n",
    "    \n",
    "    sql = \"\"\"\n",
    "select\n",
    "  a.mw_file_hash,\n",
    "  a.section_name,\n",
    "  c.mw_file_suffix as mw_file_size,\n",
    "  c.mw_file_prefix as mw_file_directory,\n",
    "  c.mw_num_engines,\n",
    "  a.pointerto_raw_data,\n",
    "  a.virtual_size,\n",
    "  d.mw_em_f\n",
    "from mw_index_2017_section_%s as a\n",
    "  right join mw_index_2017_%s c on a.mw_file_hash = c.mw_file_hash\n",
    "  right join mw_index_2017_feature_%s d on a.mw_file_hash = d.mw_file_hash\n",
    "where a.section_name = '.text' and c.mw_num_engines <> -1 and (c.mw_num_engines > 8 or c.mw_num_engines < 4) and\n",
    "      c.mw_file_prefix in ('201701')\n",
    "group by mw_file_hash\n",
    "    \"\"\" % (table_suffix, table_suffix, table_suffix)\n",
    "        \n",
    "    \n",
    "    sql2 = \"\"\"\n",
    "select\n",
    "  b.mw_file_hash,\n",
    "  b.mw_file_prefix as mw_file_directory,\n",
    "  b.mw_file_suffix as mw_file_size,\n",
    "  b.mw_num_engines,\n",
    "  a.section_name,\n",
    "  a.virtual_size,\n",
    "  a.pointerto_raw_data,\n",
    "  c.mw_em_f\n",
    "from mw_index_2017_section_%s a\n",
    "  inner join mw_index_2017_%s b on a.mw_file_hash = b.mw_file_hash\n",
    "  inner join mw_index_2017_feature_%s c on a.mw_file_hash = c.mw_file_hash\n",
    "where MEM_EXECUTE = 1 and (mw_num_engines > 8 or mw_num_engines < 4) and mw_num_engines <> -1\n",
    "      and mw_file_prefix in ('201701', '201703')\n",
    "group by b.mw_file_hash;\n",
    "    \"\"\" % (table_suffix, table_suffix, table_suffix)\n",
    "    \n",
    "    \n",
    "    sql3 = \"\"\"\n",
    "select\n",
    "  mw_file_hash,\n",
    "  mw_file_prefix as mw_file_directory,\n",
    "  mw_file_suffix as mw_file_size,\n",
    "  mw_num_engines\n",
    "from mw_index_2017_%s\n",
    "where (mw_num_engines > 8 or mw_num_engines < 4) and mw_num_engines <> -1\n",
    "      and mw_file_prefix in ('201705');\n",
    "    \"\"\" % table_suffix\n",
    "        \n",
    "        \n",
    "    sql4 = \"\"\"\n",
    "select\n",
    "  b.mw_file_hash,\n",
    "  mw_file_prefix as mw_file_directory,\n",
    "  mw_file_suffix as mw_file_size,\n",
    "  mw_num_engines,\n",
    "  a.virtual_size,\n",
    "  a.pointerto_raw_data\n",
    "from mw_index_2017_section_%s a\n",
    "  inner join mw_index_2017_%s b on a.mw_file_hash = b.mw_file_hash\n",
    "where (mw_num_engines > 8 or mw_num_engines < 4) and mw_num_engines <> -1\n",
    "      and mw_file_prefix in ('201701')\n",
    "group by b.mw_file_hash;\n",
    "    \"\"\" % (table_suffix, table_suffix)\n",
    "        \n",
    "    sql5 = \"\"\"\n",
    "select\n",
    "  a.mw_file_hash,\n",
    "  c.mw_file_prefix as mw_file_directory,\n",
    "  c.mw_file_suffix as mw_file_size,\n",
    "  c.mw_num_engines,\n",
    "  b.section_name,\n",
    "  b.virtual_size,\n",
    "  b.pointerto_raw_data,\n",
    "  d.mw_em_f\n",
    "from (select\n",
    "        mw_file_hash,\n",
    "        section_name,\n",
    "        count(1) as cnt\n",
    "      from mw_index_2017_section_%s\n",
    "      where section_name = '.text' and pointerto_raw_data <> 0\n",
    "      group by mw_file_hash, section_name) a inner join mw_index_2017_section_%s b\n",
    "    on a.mw_file_hash = b.mw_file_hash and a.cnt = 1 and b.section_name = '.text'\n",
    "  inner join mw_index_2017_%s c on a.mw_file_hash = c.mw_file_hash and (c.mw_num_engines > 8 or c.mw_num_engines < 4) and c.mw_num_engines<> -1 and c.mw_file_prefix = '201703'\n",
    "  inner join mw_index_2017_feature_%s d on a.mw_file_hash = d.mw_file_hash\n",
    "    \"\"\" % (table_suffix, table_suffix, table_suffix, table_suffix)\n",
    "    \n",
    "    cursor.execute(sql2)\n",
    "\n",
    "    field_names = [i[0] for i in cursor.description]\n",
    "\n",
    "    for row in cursor:\n",
    "        temp = {}\n",
    "        for key in range(len(row)):\n",
    "            temp[field_names[key]] = row[key]\n",
    "        ret.append(temp)\n",
    "     \n",
    "    cursor.close()\n",
    "    # _connection.close()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.431426048278809 seconds ---\n",
      "--- 11.111799955368042 seconds ---\n",
      "--- 9.329645872116089 seconds ---\n",
      "--- 11.745375871658325 seconds ---\n",
      "--- 9.812025785446167 seconds ---\n",
      "--- 9.292504787445068 seconds ---\n"
     ]
    }
   ],
   "source": [
    "close()\n",
    "res = []\n",
    "get_connection(db)\n",
    "table_suffix = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "for suffix in table_suffix:\n",
    "    res.extend(get_specific_data(suffix))\n",
    "close()\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "\n",
    "clean_data = data.loc[data.virtual_size <= 300000]\n",
    "clean_data = clean_data.reset_index(drop=True)\n",
    "\n",
    "print(clean_data.shape)\n",
    "\n",
    "h = sorted(clean_data.virtual_size.ravel())  #sorted\n",
    "\n",
    "fit = stats.norm.pdf(h, np.mean(h), np.std(h))  #this is a fitting indeed\n",
    "\n",
    "pl.plot(h,fit,'-o')\n",
    "\n",
    "pl.hist(h,normed=True)      #use this to draw histogram of your data\n",
    "\n",
    "pl.show()                   #use may also need add this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.mw_num_engines[clean_data.mw_num_engines < 4 ] = 0\n",
    "clean_data.mw_num_engines[clean_data.mw_num_engines > 8 ] = 1\n",
    "label = clean_data.mw_num_engines.ravel()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(clean_data, label, test_size=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(x_train.virtual_size.ravel())\n",
    "max_length = 299996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mal Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, list_IDs, datasets, labels, batch_size=32, dim=8192, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.datasets = datasets\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, self.dim), dtype=float)\n",
    "        y = np.zeros(self.batch_size, dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            base_path = \"/malware_data_2017/201703/{0}{1}\"\n",
    "            item = self.datasets.loc[ID]\n",
    "            file_path = base_path.format(item[\"mw_file_hash\"], item[\"mw_file_size\"])\n",
    "            in_file = open(file_path, 'rb')\n",
    "            in_file.seek(item['pointerto_raw_data'])\n",
    "            bytes_data = [int(single_byte) for single_byte in in_file.read(item['virtual_size'])]\n",
    "            X[i, 0:len(bytes_data)] = bytes_data\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras import Input\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Dense, Embedding, Conv1D, Multiply, GlobalMaxPooling1D\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TMalConv(object):\n",
    "    \"\"\"\n",
    "    train of mal conv\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_df = x_train\n",
    "        self.label_df = y_train\n",
    "        self.v_x = None\n",
    "        self.v_y = None\n",
    "        self.max_len = max_length\n",
    "        self.history = None\n",
    "        self.model = None\n",
    "        self.p_md5 = None\n",
    "        self.summary = {\n",
    "            'time':time.time(),\n",
    "            'batch_size': 16,\n",
    "            'epochs': 12,\n",
    "            's_test_size': 0.05,\n",
    "            's_random_state': 5242,\n",
    "            'g_c_filter': 128,\n",
    "            'g_c_kernel_size': 500,\n",
    "            'g_c_stride': 500,\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        \n",
    "    def get_p(self, key):\n",
    "        \"\"\"\n",
    "        get the parameter from the summary\n",
    "        :param key:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.summary[key]\n",
    "\n",
    "    def gate_cnn(self, gate_cnn_input):\n",
    "        \"\"\"\n",
    "        construct a gated cnn by the specific kernel size\n",
    "        :param gate_cnn_input:\n",
    "        :param kernel_size:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        conv1_out = Conv1D(self.get_p(\"g_c_filter\"), self.get_p(\"g_c_kernel_size\"), strides=self.get_p(\"g_c_stride\"))(\n",
    "            gate_cnn_input)\n",
    "        conv2_out = Conv1D(self.get_p(\"g_c_filter\"), self.get_p(\"g_c_kernel_size\"), strides=self.get_p(\"g_c_stride\"),\n",
    "                           activation=\"sigmoid\")(gate_cnn_input)\n",
    "        merged = Multiply()([conv1_out, conv2_out])\n",
    "        gate_cnn_output = GlobalMaxPooling1D()(merged)\n",
    "        return gate_cnn_output\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        get a model\n",
    "        :param max_len:\n",
    "        :param kernel_sizes:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        net_input = Input(shape=(self.max_len,))\n",
    "\n",
    "        embedding_out = Embedding(256, 8, input_length=self.max_len)(net_input)\n",
    "        merged = self.gate_cnn(embedding_out)\n",
    "\n",
    "        dense_out = Dense(128)(merged)\n",
    "        net_output = Dense(1, activation='sigmoid')(dense_out)\n",
    "\n",
    "        model = keras.models.Model(inputs=net_input, outputs=net_output)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        batch_size = self.get_p(\"batch_size\")\n",
    "        epochs = self.get_p(\"epochs\")\n",
    "\n",
    "        self.model = self.get_model()\n",
    "\n",
    "        partition_train, partition_validation = train_test_split(range(len(self.train_df)), test_size=0.1, random_state=1234)\n",
    "        print('Length of the train: ', len(partition_train))\n",
    "        print('Length of the validation: ', len(partition_validation))\n",
    "        \n",
    "#         tensor_board = TensorBoard(log_dir='./logs/', batch_size=batch_size)\n",
    "        file_path = \"/home/zhaoqi/BaseTrain/models/{epoch:04d}-{val_loss:.5f}-{val_acc:.5f}.h5\"\n",
    "#         early_stopping = EarlyStopping(\"val_loss\", patience=2, verbose=0, mode='auto')\n",
    "        check_point = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=False, mode='auto')\n",
    "        callbacks_list = [check_point]\n",
    "\n",
    "        # Generators\n",
    "        training_generator = DataGenerator(partition_train, self.train_df, self.label_df, batch_size, self.max_len)\n",
    "        validation_generator = DataGenerator(partition_validation, self.train_df, self.label_df, batch_size, self.max_len)\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "        self.model.fit_generator(generator=training_generator,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 use_multiprocessing=True,\n",
    "                                 epochs=epochs,\n",
    "                                 workers=12,\n",
    "                                 callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train:  75239\n",
      "Length of the validation:  8360\n",
      "Epoch 1/12\n",
      " 747/4702 [===>..........................] - ETA: 11:50 - loss: 0.1652 - acc: 0.9401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-201:\n",
      "Process ForkPoolWorker-205:\n",
      "Process ForkPoolWorker-211:\n",
      "Process ForkPoolWorker-200:\n",
      "Process ForkPoolWorker-208:\n",
      "Process ForkPoolWorker-206:\n",
      "Process ForkPoolWorker-202:\n",
      "Process ForkPoolWorker-209:\n",
      "Process ForkPoolWorker-207:\n",
      "Process ForkPoolWorker-204:\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/reduction.py\", line 50, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-104-b310e8849829>\", line 29, in __getitem__\n",
      "    X, y = self.__data_generation(list_IDs_temp)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-104-b310e8849829>\", line 52, in __data_generation\n",
      "    bytes_data = [int(single_byte) for single_byte in in_file.read(item['virtual_size'])]\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-210:\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"<ipython-input-104-b310e8849829>\", line 29, in __getitem__\n",
      "    X, y = self.__data_generation(list_IDs_temp)\n",
      "  File \"<ipython-input-104-b310e8849829>\", line 52, in __data_generation\n",
      "    bytes_data = [int(single_byte) for single_byte in in_file.read(item['virtual_size'])]\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-104-b310e8849829>\", line 52, in <listcomp>\n",
      "    bytes_data = [int(single_byte) for single_byte in in_file.read(item['virtual_size'])]\n",
      "Process ForkPoolWorker-203:\n",
      "  File \"<ipython-input-104-b310e8849829>\", line 52, in <listcomp>\n",
      "    bytes_data = [int(single_byte) for single_byte in in_file.read(item['virtual_size'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 341, in put\n",
      "    obj = ForkingPickler.dumps(obj)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/queues.py\", line 341, in put\n",
      "    obj = ForkingPickler.dumps(obj)\n",
      "  File \"/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/multiprocessing/reduction.py\", line 50, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-42acf2777b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTMalConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-1aefb51351ea>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-1aefb51351ea>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m                                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                                  \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                                  callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "t_instance = TMalConv()\n",
    "t_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/513 [==============================] - 139s 270ms/step\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/home/zhaoqi/BaseTrain/models/'\n",
    "f_name = '0006-0.12993-0.96117.h5'\n",
    "c_model = load_model(model_dir + f_name)\n",
    "test_generator = DataGenerator(range(len(x_test)), x_test, y_test, 16, max_length, False)\n",
    "y_pred = c_model.predict_generator(generator=test_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, confusion_matrix\n",
    "\n",
    "def estimate_model(y_pred, test_y):\n",
    "    \n",
    "    loss = log_loss(test_y, y_pred)\n",
    "    auc = roc_auc_score(test_y, y_pred)\n",
    "    acc = accuracy_score(test_y, (y_pred > 0.5).astype(int))\n",
    "    print(\"loss : %.5f\" % loss)\n",
    "    print(\"auc score : %.5f\" % auc)\n",
    "    print(\"accuracy score : %.5f\" % acc)\n",
    "\n",
    "    fp_np_index = np.where(test_y == 0)\n",
    "    fp_np = y_pred[fp_np_index].shape[0]\n",
    "    thre_index = int(np.ceil(fp_np - fp_np * 0.001))\n",
    "\n",
    "    sorted_pred_prob = np.sort(y_pred[fp_np_index], axis=0)\n",
    "    thre = sorted_pred_prob[thre_index]\n",
    "    if thre == 1:\n",
    "        thre = max(sorted_pred_prob[np.where(sorted_pred_prob != 1)])\n",
    "\n",
    "    y_pred_prob = np.vstack((y_pred.transpose(), (1 - y_pred).transpose())).transpose()\n",
    "    y_pred_prob[:, 1] = thre\n",
    "    y_pred_label = np.argmin(y_pred_prob, axis=-1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_y, y_pred_label).ravel()\n",
    "    fp_rate = fp / (fp + tn)\n",
    "    recall_rate = tp / (tp + fn)\n",
    "\n",
    "    print(\"thre: %.5f\"%  thre)\n",
    "    print(\"fp:  %.5f\"%  fp_rate)\n",
    "    print(\"recall:  %.5f\"%  recall_rate)\n",
    "    \n",
    "    return auc, loss, recall_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.14071\n",
      "auc score : 0.98705\n",
      "accuracy score : 0.95358\n",
      "thre: 0.99792\n",
      "fp:  0.00062\n",
      "recall:  0.72155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9870460807542742, 0.1407084855590686, 0.7215489210759681)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_model(y_pred, y_test[0:len(y_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ember_feature(data):\n",
    "    ember_f = np.zeros((len(data.mw_em_f), 2351), dtype=float)\n",
    "    for index, item in data.iterrows():\n",
    "        float_arr = item['mw_em_f'].split(';')\n",
    "        ember_f[index, :] = float_arr\n",
    "    return ember_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ember train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(data, label):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.1, random_state=1234)\n",
    "    params = {'application': 'binary'}\n",
    "    lgbm_dataset = lgb.Dataset(x_train, y_train.ravel())\n",
    "    valid_sets = lgb.Dataset(x_test, y_test.ravel())\n",
    "\n",
    "    model = lgb.train(params, lgbm_dataset, 100000, valid_sets=valid_sets, early_stopping_rounds=10)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    loss = log_loss(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "#     model.save_model(file_path + \"-%04d-%.5f-%.5f.h5\" % (model.best_iteration, loss, acc),\n",
    "#                      num_iteration=model.best_iteration)\n",
    "    print(\"val loss : %.5f\" % loss)\n",
    "    print(\"auc score : %.5f\" % auc)\n",
    "    print(\"accuracy score : %.5f\" % acc)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ember_train = get_ember_feature(x_train)\n",
    "y_ember_train = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83599, 2351)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ember_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.606705\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.538164\n",
      "[3]\tvalid_0's binary_logloss: 0.480632\n",
      "[4]\tvalid_0's binary_logloss: 0.431482\n",
      "[5]\tvalid_0's binary_logloss: 0.390057\n",
      "[6]\tvalid_0's binary_logloss: 0.353771\n",
      "[7]\tvalid_0's binary_logloss: 0.322006\n",
      "[8]\tvalid_0's binary_logloss: 0.2943\n",
      "[9]\tvalid_0's binary_logloss: 0.269763\n",
      "[10]\tvalid_0's binary_logloss: 0.248075\n",
      "[11]\tvalid_0's binary_logloss: 0.228586\n",
      "[12]\tvalid_0's binary_logloss: 0.211549\n",
      "[13]\tvalid_0's binary_logloss: 0.196008\n",
      "[14]\tvalid_0's binary_logloss: 0.182362\n",
      "[15]\tvalid_0's binary_logloss: 0.170003\n",
      "[16]\tvalid_0's binary_logloss: 0.158991\n",
      "[17]\tvalid_0's binary_logloss: 0.148514\n",
      "[18]\tvalid_0's binary_logloss: 0.139195\n",
      "[19]\tvalid_0's binary_logloss: 0.130832\n",
      "[20]\tvalid_0's binary_logloss: 0.122769\n",
      "[21]\tvalid_0's binary_logloss: 0.115702\n",
      "[22]\tvalid_0's binary_logloss: 0.109301\n",
      "[23]\tvalid_0's binary_logloss: 0.103047\n",
      "[24]\tvalid_0's binary_logloss: 0.0977112\n",
      "[25]\tvalid_0's binary_logloss: 0.092642\n",
      "[26]\tvalid_0's binary_logloss: 0.0874785\n",
      "[27]\tvalid_0's binary_logloss: 0.0831101\n",
      "[28]\tvalid_0's binary_logloss: 0.0789384\n",
      "[29]\tvalid_0's binary_logloss: 0.0754901\n",
      "[30]\tvalid_0's binary_logloss: 0.072403\n",
      "[31]\tvalid_0's binary_logloss: 0.0693371\n",
      "[32]\tvalid_0's binary_logloss: 0.0666997\n",
      "[33]\tvalid_0's binary_logloss: 0.063817\n",
      "[34]\tvalid_0's binary_logloss: 0.0614886\n",
      "[35]\tvalid_0's binary_logloss: 0.059291\n",
      "[36]\tvalid_0's binary_logloss: 0.0573777\n",
      "[37]\tvalid_0's binary_logloss: 0.055567\n",
      "[38]\tvalid_0's binary_logloss: 0.0536792\n",
      "[39]\tvalid_0's binary_logloss: 0.0521116\n",
      "[40]\tvalid_0's binary_logloss: 0.0499986\n",
      "[41]\tvalid_0's binary_logloss: 0.0484327\n",
      "[42]\tvalid_0's binary_logloss: 0.0467728\n",
      "[43]\tvalid_0's binary_logloss: 0.0455872\n",
      "[44]\tvalid_0's binary_logloss: 0.044573\n",
      "[45]\tvalid_0's binary_logloss: 0.0432152\n",
      "[46]\tvalid_0's binary_logloss: 0.0423637\n",
      "[47]\tvalid_0's binary_logloss: 0.0412847\n",
      "[48]\tvalid_0's binary_logloss: 0.0404663\n",
      "[49]\tvalid_0's binary_logloss: 0.0393322\n",
      "[50]\tvalid_0's binary_logloss: 0.0385935\n",
      "[51]\tvalid_0's binary_logloss: 0.0377118\n",
      "[52]\tvalid_0's binary_logloss: 0.0368132\n",
      "[53]\tvalid_0's binary_logloss: 0.0360548\n",
      "[54]\tvalid_0's binary_logloss: 0.0354283\n",
      "[55]\tvalid_0's binary_logloss: 0.0347369\n",
      "[56]\tvalid_0's binary_logloss: 0.0340628\n",
      "[57]\tvalid_0's binary_logloss: 0.0335007\n",
      "[58]\tvalid_0's binary_logloss: 0.0329427\n",
      "[59]\tvalid_0's binary_logloss: 0.032349\n",
      "[60]\tvalid_0's binary_logloss: 0.0318772\n",
      "[61]\tvalid_0's binary_logloss: 0.0313753\n",
      "[62]\tvalid_0's binary_logloss: 0.03095\n",
      "[63]\tvalid_0's binary_logloss: 0.0304905\n",
      "[64]\tvalid_0's binary_logloss: 0.0301581\n",
      "[65]\tvalid_0's binary_logloss: 0.029705\n",
      "[66]\tvalid_0's binary_logloss: 0.0294477\n",
      "[67]\tvalid_0's binary_logloss: 0.0289665\n",
      "[68]\tvalid_0's binary_logloss: 0.0286771\n",
      "[69]\tvalid_0's binary_logloss: 0.0283542\n",
      "[70]\tvalid_0's binary_logloss: 0.0279894\n",
      "[71]\tvalid_0's binary_logloss: 0.027757\n",
      "[72]\tvalid_0's binary_logloss: 0.0274457\n",
      "[73]\tvalid_0's binary_logloss: 0.0271775\n",
      "[74]\tvalid_0's binary_logloss: 0.0269066\n",
      "[75]\tvalid_0's binary_logloss: 0.0266844\n",
      "[76]\tvalid_0's binary_logloss: 0.0264523\n",
      "[77]\tvalid_0's binary_logloss: 0.026164\n",
      "[78]\tvalid_0's binary_logloss: 0.0258152\n",
      "[79]\tvalid_0's binary_logloss: 0.025668\n",
      "[80]\tvalid_0's binary_logloss: 0.0255023\n",
      "[81]\tvalid_0's binary_logloss: 0.0251935\n",
      "[82]\tvalid_0's binary_logloss: 0.0249563\n",
      "[83]\tvalid_0's binary_logloss: 0.0247843\n",
      "[84]\tvalid_0's binary_logloss: 0.0245991\n",
      "[85]\tvalid_0's binary_logloss: 0.0243994\n",
      "[86]\tvalid_0's binary_logloss: 0.0243566\n",
      "[87]\tvalid_0's binary_logloss: 0.0241358\n",
      "[88]\tvalid_0's binary_logloss: 0.0238315\n",
      "[89]\tvalid_0's binary_logloss: 0.023696\n",
      "[90]\tvalid_0's binary_logloss: 0.023461\n",
      "[91]\tvalid_0's binary_logloss: 0.0233347\n",
      "[92]\tvalid_0's binary_logloss: 0.0231088\n",
      "[93]\tvalid_0's binary_logloss: 0.0230431\n",
      "[94]\tvalid_0's binary_logloss: 0.0228792\n",
      "[95]\tvalid_0's binary_logloss: 0.0227415\n",
      "[96]\tvalid_0's binary_logloss: 0.0225848\n",
      "[97]\tvalid_0's binary_logloss: 0.0224267\n",
      "[98]\tvalid_0's binary_logloss: 0.0223171\n",
      "[99]\tvalid_0's binary_logloss: 0.0222244\n",
      "[100]\tvalid_0's binary_logloss: 0.0221359\n",
      "[101]\tvalid_0's binary_logloss: 0.0218903\n",
      "[102]\tvalid_0's binary_logloss: 0.0217788\n",
      "[103]\tvalid_0's binary_logloss: 0.0217132\n",
      "[104]\tvalid_0's binary_logloss: 0.0215968\n",
      "[105]\tvalid_0's binary_logloss: 0.021508\n",
      "[106]\tvalid_0's binary_logloss: 0.0214509\n",
      "[107]\tvalid_0's binary_logloss: 0.0212943\n",
      "[108]\tvalid_0's binary_logloss: 0.0212555\n",
      "[109]\tvalid_0's binary_logloss: 0.0210785\n",
      "[110]\tvalid_0's binary_logloss: 0.0210022\n",
      "[111]\tvalid_0's binary_logloss: 0.0208998\n",
      "[112]\tvalid_0's binary_logloss: 0.0207706\n",
      "[113]\tvalid_0's binary_logloss: 0.0206388\n",
      "[114]\tvalid_0's binary_logloss: 0.0205651\n",
      "[115]\tvalid_0's binary_logloss: 0.0204692\n",
      "[116]\tvalid_0's binary_logloss: 0.0203762\n",
      "[117]\tvalid_0's binary_logloss: 0.0203393\n",
      "[118]\tvalid_0's binary_logloss: 0.0203484\n",
      "[119]\tvalid_0's binary_logloss: 0.0202229\n",
      "[120]\tvalid_0's binary_logloss: 0.0201422\n",
      "[121]\tvalid_0's binary_logloss: 0.0200564\n",
      "[122]\tvalid_0's binary_logloss: 0.0200003\n",
      "[123]\tvalid_0's binary_logloss: 0.0200003\n",
      "[124]\tvalid_0's binary_logloss: 0.0198677\n",
      "[125]\tvalid_0's binary_logloss: 0.0197962\n",
      "[126]\tvalid_0's binary_logloss: 0.0197656\n",
      "[127]\tvalid_0's binary_logloss: 0.0197276\n",
      "[128]\tvalid_0's binary_logloss: 0.0196383\n",
      "[129]\tvalid_0's binary_logloss: 0.0195726\n",
      "[130]\tvalid_0's binary_logloss: 0.019502\n",
      "[131]\tvalid_0's binary_logloss: 0.019384\n",
      "[132]\tvalid_0's binary_logloss: 0.0193974\n",
      "[133]\tvalid_0's binary_logloss: 0.0193053\n",
      "[134]\tvalid_0's binary_logloss: 0.0193152\n",
      "[135]\tvalid_0's binary_logloss: 0.0192659\n",
      "[136]\tvalid_0's binary_logloss: 0.0191654\n",
      "[137]\tvalid_0's binary_logloss: 0.0190995\n",
      "[138]\tvalid_0's binary_logloss: 0.0190357\n",
      "[139]\tvalid_0's binary_logloss: 0.0189991\n",
      "[140]\tvalid_0's binary_logloss: 0.0189192\n",
      "[141]\tvalid_0's binary_logloss: 0.0189184\n",
      "[142]\tvalid_0's binary_logloss: 0.0189001\n",
      "[143]\tvalid_0's binary_logloss: 0.0188435\n",
      "[144]\tvalid_0's binary_logloss: 0.0188142\n",
      "[145]\tvalid_0's binary_logloss: 0.0187944\n",
      "[146]\tvalid_0's binary_logloss: 0.0187382\n",
      "[147]\tvalid_0's binary_logloss: 0.0186981\n",
      "[148]\tvalid_0's binary_logloss: 0.0187022\n",
      "[149]\tvalid_0's binary_logloss: 0.0186606\n",
      "[150]\tvalid_0's binary_logloss: 0.0186177\n",
      "[151]\tvalid_0's binary_logloss: 0.0185901\n",
      "[152]\tvalid_0's binary_logloss: 0.0185308\n",
      "[153]\tvalid_0's binary_logloss: 0.0185055\n",
      "[154]\tvalid_0's binary_logloss: 0.0184356\n",
      "[155]\tvalid_0's binary_logloss: 0.0184353\n",
      "[156]\tvalid_0's binary_logloss: 0.0183958\n",
      "[157]\tvalid_0's binary_logloss: 0.0183424\n",
      "[158]\tvalid_0's binary_logloss: 0.0182632\n",
      "[159]\tvalid_0's binary_logloss: 0.0182102\n",
      "[160]\tvalid_0's binary_logloss: 0.0182051\n",
      "[161]\tvalid_0's binary_logloss: 0.0180907\n",
      "[162]\tvalid_0's binary_logloss: 0.0180585\n",
      "[163]\tvalid_0's binary_logloss: 0.017987\n",
      "[164]\tvalid_0's binary_logloss: 0.0180029\n",
      "[165]\tvalid_0's binary_logloss: 0.017954\n",
      "[166]\tvalid_0's binary_logloss: 0.0179225\n",
      "[167]\tvalid_0's binary_logloss: 0.0179356\n",
      "[168]\tvalid_0's binary_logloss: 0.0179016\n",
      "[169]\tvalid_0's binary_logloss: 0.0179104\n",
      "[170]\tvalid_0's binary_logloss: 0.0179589\n",
      "[171]\tvalid_0's binary_logloss: 0.0178996\n",
      "[172]\tvalid_0's binary_logloss: 0.0178451\n",
      "[173]\tvalid_0's binary_logloss: 0.0178304\n",
      "[174]\tvalid_0's binary_logloss: 0.0177483\n",
      "[175]\tvalid_0's binary_logloss: 0.0177453\n",
      "[176]\tvalid_0's binary_logloss: 0.0177213\n",
      "[177]\tvalid_0's binary_logloss: 0.0176456\n",
      "[178]\tvalid_0's binary_logloss: 0.0176372\n",
      "[179]\tvalid_0's binary_logloss: 0.0176082\n",
      "[180]\tvalid_0's binary_logloss: 0.017603\n",
      "[181]\tvalid_0's binary_logloss: 0.0175544\n",
      "[182]\tvalid_0's binary_logloss: 0.0175021\n",
      "[183]\tvalid_0's binary_logloss: 0.0174311\n",
      "[184]\tvalid_0's binary_logloss: 0.0174196\n",
      "[185]\tvalid_0's binary_logloss: 0.0173757\n",
      "[186]\tvalid_0's binary_logloss: 0.0173669\n",
      "[187]\tvalid_0's binary_logloss: 0.0173026\n",
      "[188]\tvalid_0's binary_logloss: 0.0172835\n",
      "[189]\tvalid_0's binary_logloss: 0.0172789\n",
      "[190]\tvalid_0's binary_logloss: 0.0173017\n",
      "[191]\tvalid_0's binary_logloss: 0.0172908\n",
      "[192]\tvalid_0's binary_logloss: 0.0172536\n",
      "[193]\tvalid_0's binary_logloss: 0.0172348\n",
      "[194]\tvalid_0's binary_logloss: 0.0172287\n",
      "[195]\tvalid_0's binary_logloss: 0.0172002\n",
      "[196]\tvalid_0's binary_logloss: 0.0171499\n",
      "[197]\tvalid_0's binary_logloss: 0.0171518\n",
      "[198]\tvalid_0's binary_logloss: 0.0171247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199]\tvalid_0's binary_logloss: 0.0171568\n",
      "[200]\tvalid_0's binary_logloss: 0.0171378\n",
      "[201]\tvalid_0's binary_logloss: 0.0171202\n",
      "[202]\tvalid_0's binary_logloss: 0.0170908\n",
      "[203]\tvalid_0's binary_logloss: 0.0170418\n",
      "[204]\tvalid_0's binary_logloss: 0.0170329\n",
      "[205]\tvalid_0's binary_logloss: 0.0170123\n",
      "[206]\tvalid_0's binary_logloss: 0.0170025\n",
      "[207]\tvalid_0's binary_logloss: 0.0169855\n",
      "[208]\tvalid_0's binary_logloss: 0.0169326\n",
      "[209]\tvalid_0's binary_logloss: 0.0169537\n",
      "[210]\tvalid_0's binary_logloss: 0.0169676\n",
      "[211]\tvalid_0's binary_logloss: 0.0169786\n",
      "[212]\tvalid_0's binary_logloss: 0.0170085\n",
      "[213]\tvalid_0's binary_logloss: 0.0169838\n",
      "[214]\tvalid_0's binary_logloss: 0.016971\n",
      "[215]\tvalid_0's binary_logloss: 0.016944\n",
      "[216]\tvalid_0's binary_logloss: 0.0168979\n",
      "[217]\tvalid_0's binary_logloss: 0.0169188\n",
      "[218]\tvalid_0's binary_logloss: 0.0169076\n",
      "[219]\tvalid_0's binary_logloss: 0.0169059\n",
      "[220]\tvalid_0's binary_logloss: 0.0169407\n",
      "[221]\tvalid_0's binary_logloss: 0.0169343\n",
      "[222]\tvalid_0's binary_logloss: 0.016898\n",
      "[223]\tvalid_0's binary_logloss: 0.0169269\n",
      "[224]\tvalid_0's binary_logloss: 0.0169106\n",
      "[225]\tvalid_0's binary_logloss: 0.0168417\n",
      "[226]\tvalid_0's binary_logloss: 0.016853\n",
      "[227]\tvalid_0's binary_logloss: 0.0168034\n",
      "[228]\tvalid_0's binary_logloss: 0.0167185\n",
      "[229]\tvalid_0's binary_logloss: 0.0167229\n",
      "[230]\tvalid_0's binary_logloss: 0.016744\n",
      "[231]\tvalid_0's binary_logloss: 0.0167097\n",
      "[232]\tvalid_0's binary_logloss: 0.0167678\n",
      "[233]\tvalid_0's binary_logloss: 0.0167817\n",
      "[234]\tvalid_0's binary_logloss: 0.0167083\n",
      "[235]\tvalid_0's binary_logloss: 0.0167132\n",
      "[236]\tvalid_0's binary_logloss: 0.0166889\n",
      "[237]\tvalid_0's binary_logloss: 0.0167181\n",
      "[238]\tvalid_0's binary_logloss: 0.0167703\n",
      "[239]\tvalid_0's binary_logloss: 0.0167586\n",
      "[240]\tvalid_0's binary_logloss: 0.016761\n",
      "[241]\tvalid_0's binary_logloss: 0.0167402\n",
      "[242]\tvalid_0's binary_logloss: 0.0167535\n",
      "[243]\tvalid_0's binary_logloss: 0.0167039\n",
      "[244]\tvalid_0's binary_logloss: 0.0166996\n",
      "[245]\tvalid_0's binary_logloss: 0.0166363\n",
      "[246]\tvalid_0's binary_logloss: 0.0166654\n",
      "[247]\tvalid_0's binary_logloss: 0.0166394\n",
      "[248]\tvalid_0's binary_logloss: 0.0166048\n",
      "[249]\tvalid_0's binary_logloss: 0.016601\n",
      "[250]\tvalid_0's binary_logloss: 0.0165813\n",
      "[251]\tvalid_0's binary_logloss: 0.0165794\n",
      "[252]\tvalid_0's binary_logloss: 0.016558\n",
      "[253]\tvalid_0's binary_logloss: 0.0165401\n",
      "[254]\tvalid_0's binary_logloss: 0.0165566\n",
      "[255]\tvalid_0's binary_logloss: 0.0165474\n",
      "[256]\tvalid_0's binary_logloss: 0.0165114\n",
      "[257]\tvalid_0's binary_logloss: 0.0165417\n",
      "[258]\tvalid_0's binary_logloss: 0.0164923\n",
      "[259]\tvalid_0's binary_logloss: 0.0164949\n",
      "[260]\tvalid_0's binary_logloss: 0.0165298\n",
      "[261]\tvalid_0's binary_logloss: 0.016521\n",
      "[262]\tvalid_0's binary_logloss: 0.0165059\n",
      "[263]\tvalid_0's binary_logloss: 0.0165158\n",
      "[264]\tvalid_0's binary_logloss: 0.0165566\n",
      "[265]\tvalid_0's binary_logloss: 0.0165385\n",
      "[266]\tvalid_0's binary_logloss: 0.0164862\n",
      "[267]\tvalid_0's binary_logloss: 0.0164686\n",
      "[268]\tvalid_0's binary_logloss: 0.0164983\n",
      "[269]\tvalid_0's binary_logloss: 0.0164722\n",
      "[270]\tvalid_0's binary_logloss: 0.016486\n",
      "[271]\tvalid_0's binary_logloss: 0.0165089\n",
      "[272]\tvalid_0's binary_logloss: 0.0164777\n",
      "[273]\tvalid_0's binary_logloss: 0.0164291\n",
      "[274]\tvalid_0's binary_logloss: 0.016432\n",
      "[275]\tvalid_0's binary_logloss: 0.0164516\n",
      "[276]\tvalid_0's binary_logloss: 0.0164242\n",
      "[277]\tvalid_0's binary_logloss: 0.0164215\n",
      "[278]\tvalid_0's binary_logloss: 0.0164369\n",
      "[279]\tvalid_0's binary_logloss: 0.016419\n",
      "[280]\tvalid_0's binary_logloss: 0.0164159\n",
      "[281]\tvalid_0's binary_logloss: 0.016413\n",
      "[282]\tvalid_0's binary_logloss: 0.0164299\n",
      "[283]\tvalid_0's binary_logloss: 0.0164182\n",
      "[284]\tvalid_0's binary_logloss: 0.0164184\n",
      "[285]\tvalid_0's binary_logloss: 0.0164558\n",
      "[286]\tvalid_0's binary_logloss: 0.0165235\n",
      "[287]\tvalid_0's binary_logloss: 0.0165561\n",
      "[288]\tvalid_0's binary_logloss: 0.0166124\n",
      "[289]\tvalid_0's binary_logloss: 0.0166103\n",
      "[290]\tvalid_0's binary_logloss: 0.0165926\n",
      "[291]\tvalid_0's binary_logloss: 0.0166089\n",
      "Early stopping, best iteration is:\n",
      "[281]\tvalid_0's binary_logloss: 0.016413\n",
      "val loss : 0.01641\n",
      "auc score : 0.99980\n",
      "accuracy score : 0.99462\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model = get_model(X_ember_train, y_ember_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ember test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ember_test = get_ember_feature(x_test)\n",
    "y_ember_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.20951\n",
      "auc score : 0.99284\n",
      "accuracy score : 0.95592\n",
      "thre: 0.99972\n",
      "fp:  0.00062\n",
      "recall:  0.71602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9928395083486442, 0.20951220307005827, 0.7160165484633569)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = model.predict(X_ember_test)\n",
    "y_pred_e = np.zeros((len(y_p), 1))\n",
    "for i in range(len(y_p)):\n",
    "    y_pred_e[i, 0] = y_p[i]\n",
    "\n",
    "estimate_model(y_pred_e, y_ember_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mal Conv + Ember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get 128 features from the last layers of Malconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4619/4619 [==============================] - 1249s 270ms/step\n",
      "513/513 [==============================] - 144s 281ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model_f = Model(c_model.input, c_model.layers[-2].output)\n",
    "\n",
    "train_generator = DataGenerator(range(len(x_train)), x_train, y_train, 16, max_length, False)\n",
    "malcon_train_x = model_f.predict_generator(generator=train_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)\n",
    "\n",
    "test_generator = DataGenerator(range(len(x_test)), x_test, y_test, 16, max_length, False)\n",
    "malcon_test_x = model_f.predict_generator(generator=test_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge mal conv and ember *train* data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.606903\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.53851\n",
      "[3]\tvalid_0's binary_logloss: 0.481297\n",
      "[4]\tvalid_0's binary_logloss: 0.433021\n",
      "[5]\tvalid_0's binary_logloss: 0.391424\n",
      "[6]\tvalid_0's binary_logloss: 0.355563\n",
      "[7]\tvalid_0's binary_logloss: 0.32417\n",
      "[8]\tvalid_0's binary_logloss: 0.296084\n",
      "[9]\tvalid_0's binary_logloss: 0.271401\n",
      "[10]\tvalid_0's binary_logloss: 0.250009\n",
      "[11]\tvalid_0's binary_logloss: 0.230353\n",
      "[12]\tvalid_0's binary_logloss: 0.213244\n",
      "[13]\tvalid_0's binary_logloss: 0.197991\n",
      "[14]\tvalid_0's binary_logloss: 0.183817\n",
      "[15]\tvalid_0's binary_logloss: 0.171655\n",
      "[16]\tvalid_0's binary_logloss: 0.160104\n",
      "[17]\tvalid_0's binary_logloss: 0.14963\n",
      "[18]\tvalid_0's binary_logloss: 0.140102\n",
      "[19]\tvalid_0's binary_logloss: 0.131657\n",
      "[20]\tvalid_0's binary_logloss: 0.124192\n",
      "[21]\tvalid_0's binary_logloss: 0.117441\n",
      "[22]\tvalid_0's binary_logloss: 0.110525\n",
      "[23]\tvalid_0's binary_logloss: 0.104306\n",
      "[24]\tvalid_0's binary_logloss: 0.0987371\n",
      "[25]\tvalid_0's binary_logloss: 0.0934087\n",
      "[26]\tvalid_0's binary_logloss: 0.0885128\n",
      "[27]\tvalid_0's binary_logloss: 0.083892\n",
      "[28]\tvalid_0's binary_logloss: 0.079944\n",
      "[29]\tvalid_0's binary_logloss: 0.0765325\n",
      "[30]\tvalid_0's binary_logloss: 0.0734992\n",
      "[31]\tvalid_0's binary_logloss: 0.0705146\n",
      "[32]\tvalid_0's binary_logloss: 0.0676826\n",
      "[33]\tvalid_0's binary_logloss: 0.0646139\n",
      "[34]\tvalid_0's binary_logloss: 0.0619407\n",
      "[35]\tvalid_0's binary_logloss: 0.0597885\n",
      "[36]\tvalid_0's binary_logloss: 0.0575717\n",
      "[37]\tvalid_0's binary_logloss: 0.0558039\n",
      "[38]\tvalid_0's binary_logloss: 0.0541453\n",
      "[39]\tvalid_0's binary_logloss: 0.0520793\n",
      "[40]\tvalid_0's binary_logloss: 0.050695\n",
      "[41]\tvalid_0's binary_logloss: 0.0494018\n",
      "[42]\tvalid_0's binary_logloss: 0.0478182\n",
      "[43]\tvalid_0's binary_logloss: 0.0465006\n",
      "[44]\tvalid_0's binary_logloss: 0.0451947\n",
      "[45]\tvalid_0's binary_logloss: 0.0441731\n",
      "[46]\tvalid_0's binary_logloss: 0.0431485\n",
      "[47]\tvalid_0's binary_logloss: 0.0419599\n",
      "[48]\tvalid_0's binary_logloss: 0.0410958\n",
      "[49]\tvalid_0's binary_logloss: 0.040331\n",
      "[50]\tvalid_0's binary_logloss: 0.0394888\n",
      "[51]\tvalid_0's binary_logloss: 0.0387788\n",
      "[52]\tvalid_0's binary_logloss: 0.0379859\n",
      "[53]\tvalid_0's binary_logloss: 0.0371861\n",
      "[54]\tvalid_0's binary_logloss: 0.0366111\n",
      "[55]\tvalid_0's binary_logloss: 0.0360041\n",
      "[56]\tvalid_0's binary_logloss: 0.0355257\n",
      "[57]\tvalid_0's binary_logloss: 0.0349534\n",
      "[58]\tvalid_0's binary_logloss: 0.0343399\n",
      "[59]\tvalid_0's binary_logloss: 0.0339101\n",
      "[60]\tvalid_0's binary_logloss: 0.0334301\n",
      "[61]\tvalid_0's binary_logloss: 0.0330088\n",
      "[62]\tvalid_0's binary_logloss: 0.0326092\n",
      "[63]\tvalid_0's binary_logloss: 0.0321587\n",
      "[64]\tvalid_0's binary_logloss: 0.0317577\n",
      "[65]\tvalid_0's binary_logloss: 0.0314106\n",
      "[66]\tvalid_0's binary_logloss: 0.0310432\n",
      "[67]\tvalid_0's binary_logloss: 0.0306967\n",
      "[68]\tvalid_0's binary_logloss: 0.0303184\n",
      "[69]\tvalid_0's binary_logloss: 0.0300725\n",
      "[70]\tvalid_0's binary_logloss: 0.0297887\n",
      "[71]\tvalid_0's binary_logloss: 0.0295719\n",
      "[72]\tvalid_0's binary_logloss: 0.0293801\n",
      "[73]\tvalid_0's binary_logloss: 0.0290303\n",
      "[74]\tvalid_0's binary_logloss: 0.0287432\n",
      "[75]\tvalid_0's binary_logloss: 0.0283945\n",
      "[76]\tvalid_0's binary_logloss: 0.0280788\n",
      "[77]\tvalid_0's binary_logloss: 0.0278843\n",
      "[78]\tvalid_0's binary_logloss: 0.0276741\n",
      "[79]\tvalid_0's binary_logloss: 0.0274526\n",
      "[80]\tvalid_0's binary_logloss: 0.0270828\n",
      "[81]\tvalid_0's binary_logloss: 0.0269334\n",
      "[82]\tvalid_0's binary_logloss: 0.0267192\n",
      "[83]\tvalid_0's binary_logloss: 0.0266025\n",
      "[84]\tvalid_0's binary_logloss: 0.0264146\n",
      "[85]\tvalid_0's binary_logloss: 0.026297\n",
      "[86]\tvalid_0's binary_logloss: 0.0261606\n",
      "[87]\tvalid_0's binary_logloss: 0.0261524\n",
      "[88]\tvalid_0's binary_logloss: 0.025963\n",
      "[89]\tvalid_0's binary_logloss: 0.0257556\n",
      "[90]\tvalid_0's binary_logloss: 0.0256076\n",
      "[91]\tvalid_0's binary_logloss: 0.0255068\n",
      "[92]\tvalid_0's binary_logloss: 0.0254078\n",
      "[93]\tvalid_0's binary_logloss: 0.0252463\n",
      "[94]\tvalid_0's binary_logloss: 0.0250828\n",
      "[95]\tvalid_0's binary_logloss: 0.0250256\n",
      "[96]\tvalid_0's binary_logloss: 0.0248978\n",
      "[97]\tvalid_0's binary_logloss: 0.0248349\n",
      "[98]\tvalid_0's binary_logloss: 0.0246451\n",
      "[99]\tvalid_0's binary_logloss: 0.024525\n",
      "[100]\tvalid_0's binary_logloss: 0.0244563\n",
      "[101]\tvalid_0's binary_logloss: 0.0243389\n",
      "[102]\tvalid_0's binary_logloss: 0.0243787\n",
      "[103]\tvalid_0's binary_logloss: 0.0243034\n",
      "[104]\tvalid_0's binary_logloss: 0.0241763\n",
      "[105]\tvalid_0's binary_logloss: 0.0241108\n",
      "[106]\tvalid_0's binary_logloss: 0.0240302\n",
      "[107]\tvalid_0's binary_logloss: 0.0240524\n",
      "[108]\tvalid_0's binary_logloss: 0.0238915\n",
      "[109]\tvalid_0's binary_logloss: 0.0237349\n",
      "[110]\tvalid_0's binary_logloss: 0.0236605\n",
      "[111]\tvalid_0's binary_logloss: 0.0235815\n",
      "[112]\tvalid_0's binary_logloss: 0.0235767\n",
      "[113]\tvalid_0's binary_logloss: 0.0234684\n",
      "[114]\tvalid_0's binary_logloss: 0.0233929\n",
      "[115]\tvalid_0's binary_logloss: 0.0233441\n",
      "[116]\tvalid_0's binary_logloss: 0.0232909\n",
      "[117]\tvalid_0's binary_logloss: 0.0231971\n",
      "[118]\tvalid_0's binary_logloss: 0.0230931\n",
      "[119]\tvalid_0's binary_logloss: 0.023009\n",
      "[120]\tvalid_0's binary_logloss: 0.0229227\n",
      "[121]\tvalid_0's binary_logloss: 0.0228474\n",
      "[122]\tvalid_0's binary_logloss: 0.0227669\n",
      "[123]\tvalid_0's binary_logloss: 0.0227066\n",
      "[124]\tvalid_0's binary_logloss: 0.022612\n",
      "[125]\tvalid_0's binary_logloss: 0.0225843\n",
      "[126]\tvalid_0's binary_logloss: 0.022492\n",
      "[127]\tvalid_0's binary_logloss: 0.022438\n",
      "[128]\tvalid_0's binary_logloss: 0.0223853\n",
      "[129]\tvalid_0's binary_logloss: 0.022272\n",
      "[130]\tvalid_0's binary_logloss: 0.0222062\n",
      "[131]\tvalid_0's binary_logloss: 0.0221639\n",
      "[132]\tvalid_0's binary_logloss: 0.0221501\n",
      "[133]\tvalid_0's binary_logloss: 0.0220979\n",
      "[134]\tvalid_0's binary_logloss: 0.0220643\n",
      "[135]\tvalid_0's binary_logloss: 0.0219828\n",
      "[136]\tvalid_0's binary_logloss: 0.0219164\n",
      "[137]\tvalid_0's binary_logloss: 0.0218803\n",
      "[138]\tvalid_0's binary_logloss: 0.0218844\n",
      "[139]\tvalid_0's binary_logloss: 0.0218406\n",
      "[140]\tvalid_0's binary_logloss: 0.0218402\n",
      "[141]\tvalid_0's binary_logloss: 0.021801\n",
      "[142]\tvalid_0's binary_logloss: 0.0217142\n",
      "[143]\tvalid_0's binary_logloss: 0.0216687\n",
      "[144]\tvalid_0's binary_logloss: 0.0216839\n",
      "[145]\tvalid_0's binary_logloss: 0.0216541\n",
      "[146]\tvalid_0's binary_logloss: 0.0216612\n",
      "[147]\tvalid_0's binary_logloss: 0.0216466\n",
      "[148]\tvalid_0's binary_logloss: 0.0216169\n",
      "[149]\tvalid_0's binary_logloss: 0.0215306\n",
      "[150]\tvalid_0's binary_logloss: 0.0214986\n",
      "[151]\tvalid_0's binary_logloss: 0.0215356\n",
      "[152]\tvalid_0's binary_logloss: 0.02149\n",
      "[153]\tvalid_0's binary_logloss: 0.0215334\n",
      "[154]\tvalid_0's binary_logloss: 0.0214802\n",
      "[155]\tvalid_0's binary_logloss: 0.0214951\n",
      "[156]\tvalid_0's binary_logloss: 0.0214847\n",
      "[157]\tvalid_0's binary_logloss: 0.0214833\n",
      "[158]\tvalid_0's binary_logloss: 0.0214622\n",
      "[159]\tvalid_0's binary_logloss: 0.0213527\n",
      "[160]\tvalid_0's binary_logloss: 0.0213001\n",
      "[161]\tvalid_0's binary_logloss: 0.0212311\n",
      "[162]\tvalid_0's binary_logloss: 0.021208\n",
      "[163]\tvalid_0's binary_logloss: 0.0211866\n",
      "[164]\tvalid_0's binary_logloss: 0.0211746\n",
      "[165]\tvalid_0's binary_logloss: 0.0212038\n",
      "[166]\tvalid_0's binary_logloss: 0.0211717\n",
      "[167]\tvalid_0's binary_logloss: 0.0211974\n",
      "[168]\tvalid_0's binary_logloss: 0.0211559\n",
      "[169]\tvalid_0's binary_logloss: 0.0211018\n",
      "[170]\tvalid_0's binary_logloss: 0.0210559\n",
      "[171]\tvalid_0's binary_logloss: 0.0210406\n",
      "[172]\tvalid_0's binary_logloss: 0.0210446\n",
      "[173]\tvalid_0's binary_logloss: 0.0209972\n",
      "[174]\tvalid_0's binary_logloss: 0.0209714\n",
      "[175]\tvalid_0's binary_logloss: 0.0209278\n",
      "[176]\tvalid_0's binary_logloss: 0.0209995\n",
      "[177]\tvalid_0's binary_logloss: 0.0209541\n",
      "[178]\tvalid_0's binary_logloss: 0.0208542\n",
      "[179]\tvalid_0's binary_logloss: 0.020837\n",
      "[180]\tvalid_0's binary_logloss: 0.0208479\n",
      "[181]\tvalid_0's binary_logloss: 0.0208625\n",
      "[182]\tvalid_0's binary_logloss: 0.020768\n",
      "[183]\tvalid_0's binary_logloss: 0.0207235\n",
      "[184]\tvalid_0's binary_logloss: 0.0207203\n",
      "[185]\tvalid_0's binary_logloss: 0.0207127\n",
      "[186]\tvalid_0's binary_logloss: 0.0206928\n",
      "[187]\tvalid_0's binary_logloss: 0.0206658\n",
      "[188]\tvalid_0's binary_logloss: 0.0206206\n",
      "[189]\tvalid_0's binary_logloss: 0.0206349\n",
      "[190]\tvalid_0's binary_logloss: 0.0206496\n",
      "[191]\tvalid_0's binary_logloss: 0.020669\n",
      "[192]\tvalid_0's binary_logloss: 0.0206514\n",
      "[193]\tvalid_0's binary_logloss: 0.0206569\n",
      "[194]\tvalid_0's binary_logloss: 0.0207191\n",
      "[195]\tvalid_0's binary_logloss: 0.0207327\n",
      "[196]\tvalid_0's binary_logloss: 0.020693\n",
      "[197]\tvalid_0's binary_logloss: 0.0207657\n",
      "[198]\tvalid_0's binary_logloss: 0.0207537\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.0206206\n",
      "val loss : 0.02062\n",
      "auc score : 0.99963\n",
      "accuracy score : 0.99418\n"
     ]
    }
   ],
   "source": [
    "num = len(malcon_train_x)\n",
    "ebm_X = np.zeros((num, 2351+128), dtype=float)\n",
    "ebm_y = np.zeros(num, dtype=float)\n",
    "\n",
    "for index in range(num):\n",
    "    ebm_X[index, 0:2351] = X_ember_train[index]\n",
    "    ebm_X[index, 2351:2351+128] = malcon_train_x[index]\n",
    "    ebm_y[index] = y_ember_train[index]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "model_m = get_model(ebm_X, ebm_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge mal conv and ember *test* data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(malcon_test_x)\n",
    "ebm_X_t = np.zeros((num, 2351+128), dtype=float)\n",
    "ebm_y_t = np.zeros(num, dtype=float)\n",
    "\n",
    "for index in range(num):\n",
    "    ebm_X_t[index, 0:2351] = X_ember_test[index]\n",
    "    ebm_X_t[index, 2351:2351+128] = malcon_test_x[index]\n",
    "    ebm_y_t[index] = y_ember_test[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.18107\n",
      "auc score : 0.99241\n",
      "accuracy score : 0.95565\n",
      "thre: 0.99873\n",
      "fp:  0.00062\n",
      "recall:  0.74254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9924079403417576, 0.1810718398054507, 0.7425362104640851)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = model_m.predict(ebm_X_t)\n",
    "y_pred = np.zeros((len(y_p), 1))\n",
    "for i in range(len(y_p)):\n",
    "    y_pred[i, 0] = y_p[i]\n",
    "\n",
    "estimate_model(y_pred, ebm_y_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
