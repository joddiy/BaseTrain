{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# specify which GPU will be used\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pymysql\n",
    "from warnings import filterwarnings\n",
    "\n",
    "_connection = None\n",
    "\n",
    "def get_connection(db_config):\n",
    "    \"\"\"\n",
    "    get db connection\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global _connection\n",
    "    if _connection is None:\n",
    "        _connection = pymysql.connect(host=db_config['host'], user=db_config['username'],\n",
    "                                      password=db_config['password'],\n",
    "                                      db=db_config['db'], charset=\"utf8\")\n",
    "        filterwarnings('ignore', category=pymysql.Warning)\n",
    "\n",
    "    return _connection\n",
    "\n",
    "\n",
    "def close():\n",
    "    \"\"\"\n",
    "    close DB connection\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global _connection\n",
    "    if _connection is not None:\n",
    "        _connection.close()\n",
    "    _connection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = {\n",
    "    'host': '172.26.187.242',\n",
    "    'username': 'malware_r',\n",
    "    'password': 'GEg22v2O7jbfWhb3',\n",
    "    'db': 'malware'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fields\n",
    "\n",
    "- mw_file_suffix: file name after hash value\n",
    "- mw_file_prefix: directory\n",
    "- mw_em_f: features of ember, splitted by \";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# the base function which can query sql and return dict data\n",
    "def get_specific_data(table_suffix, sql=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    global _connection\n",
    "    if _connection is None:\n",
    "        raise Exception(\"please init db connect first\")\n",
    "\n",
    "    cursor = _connection.cursor()\n",
    "    cursor.execute(\"SET NAMES utf8mb4\")\n",
    "\n",
    "    ret = []\n",
    "        \n",
    "    cursor.execute(sql)\n",
    "\n",
    "    field_names = [i[0] for i in cursor.description]\n",
    "\n",
    "    for row in cursor:\n",
    "        temp = {}\n",
    "        for key in range(len(row)):\n",
    "            temp[field_names[key]] = row[key]\n",
    "        ret.append(temp)\n",
    "     \n",
    "    cursor.close()\n",
    "    # _connection.close()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.104015350341797 seconds ---\n",
      "--- 3.212686777114868 seconds ---\n",
      "--- 3.265317916870117 seconds ---\n",
      "--- 3.009309768676758 seconds ---\n",
      "--- 2.8050670623779297 seconds ---\n",
      "--- 2.946202516555786 seconds ---\n",
      "--- 3.236978769302368 seconds ---\n",
      "--- 2.8308823108673096 seconds ---\n",
      "--- 2.8081748485565186 seconds ---\n",
      "--- 3.0357909202575684 seconds ---\n",
      "--- 2.600412607192993 seconds ---\n",
      "--- 2.379838228225708 seconds ---\n",
      "--- 2.6680760383605957 seconds ---\n",
      "--- 1.8274145126342773 seconds ---\n",
      "--- 1.811929702758789 seconds ---\n",
      "--- 1.8530206680297852 seconds ---\n",
      "127160\n"
     ]
    }
   ],
   "source": [
    "close()\n",
    "res1 = []\n",
    "get_connection(db)\n",
    "table_suffix = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "# Iterate all partitions of databases\n",
    "for suffix in table_suffix:\n",
    "    sql = \"\"\" \n",
    "select\n",
    "  a.mw_file_hash,\n",
    "  a.section_name,\n",
    "  c.mw_file_suffix as mw_file_size,\n",
    "  c.mw_file_prefix as mw_file_directory,\n",
    "  c.mw_num_engines,\n",
    "  a.pointerto_raw_data,\n",
    "  a.virtual_size,\n",
    "  d.mw_em_f\n",
    "from mw_index_2017_section_%s as a\n",
    "  inner join mw_index_2017_%s c on a.mw_file_hash = c.mw_file_hash\n",
    "  inner join mw_index_2017_feature_%s d on a.mw_file_hash = d.mw_file_hash\n",
    "where a.section_name = '.text' and c.mw_num_engines <> -1 and (c.mw_num_engines > 6 or c.mw_num_engines = 0) and\n",
    "      c.mw_file_prefix in ('201701')\n",
    "group by mw_file_hash\n",
    "    \"\"\" % (suffix, suffix, suffix)\n",
    "    res1.extend(get_specific_data(suffix, sql))\n",
    "close()\n",
    "print(len(res1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.697957992553711 seconds ---\n",
      "--- 7.296715259552002 seconds ---\n",
      "--- 4.503918170928955 seconds ---\n",
      "--- 4.409035921096802 seconds ---\n",
      "--- 4.349301099777222 seconds ---\n",
      "--- 4.44843316078186 seconds ---\n",
      "--- 4.423307657241821 seconds ---\n",
      "--- 4.492370128631592 seconds ---\n",
      "--- 4.422391176223755 seconds ---\n",
      "--- 6.929706811904907 seconds ---\n",
      "--- 4.831637144088745 seconds ---\n",
      "--- 4.639912843704224 seconds ---\n",
      "--- 4.666112899780273 seconds ---\n",
      "--- 4.807678461074829 seconds ---\n",
      "--- 5.224670171737671 seconds ---\n",
      "--- 5.1271138191223145 seconds ---\n",
      "84582\n"
     ]
    }
   ],
   "source": [
    "close()\n",
    "res2 = []\n",
    "get_connection(db)\n",
    "table_suffix = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "# Iterate all partitions of databases\n",
    "for suffix in table_suffix:\n",
    "    sql = \"\"\" \n",
    "select\n",
    "  a.mw_file_hash,\n",
    "  a.section_name,\n",
    "  c.mw_file_suffix as mw_file_size,\n",
    "  c.mw_file_prefix as mw_file_directory,\n",
    "  c.mw_num_engines,\n",
    "  a.pointerto_raw_data,\n",
    "  a.virtual_size,\n",
    "  d.mw_em_f\n",
    "from mw_index_2017_section_%s as a\n",
    "  inner join mw_index_2017_%s c on a.mw_file_hash = c.mw_file_hash\n",
    "  inner join mw_index_2017_feature_%s d on a.mw_file_hash = d.mw_file_hash\n",
    "where a.section_name = '.text' and c.mw_num_engines <> -1 and (c.mw_num_engines > 6 or c.mw_num_engines = 0) and\n",
    "      c.mw_file_prefix in ('201702')\n",
    "group by mw_file_hash\n",
    "    \"\"\" % (suffix, suffix, suffix)\n",
    "    res2.extend(get_specific_data(suffix, sql))\n",
    "close()\n",
    "print(len(res2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhaoqi/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_length = 300000\n",
    "\n",
    "train_data = pd.DataFrame(res1)\n",
    "train_data = train_data.loc[train_data.virtual_size <= max_length]\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "train_data.mw_num_engines[train_data.mw_num_engines == 0 ] = 0\n",
    "train_data.mw_num_engines[train_data.mw_num_engines > 6 ] = 1\n",
    "train_label = train_data.mw_num_engines.ravel()\n",
    "\n",
    "test_data = pd.DataFrame(res2)\n",
    "test_data = test_data.loc[test_data.virtual_size <= max_length]\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "test_data.mw_num_engines[test_data.mw_num_engines == 0 ] = 0\n",
    "test_data.mw_num_engines[test_data.mw_num_engines > 6 ] = 1\n",
    "test_label = test_data.mw_num_engines.ravel()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data, train_label, test_size=0.1, random_state=2345)\n",
    "x_test = test_data\n",
    "y_test = test_label\n",
    "\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "x_val = x_val.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ember_feature(data):\n",
    "    ember_f = np.zeros((len(data.mw_em_f), 2351), dtype=float)\n",
    "    for index, item in data.iterrows():\n",
    "        ember_f[index, :] = item['mw_em_f'].split(';')\n",
    "    return ember_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_train, y_train, x_val, y_val):\n",
    "    params = {'application': 'binary'}\n",
    "    lgbm_dataset = lgb.Dataset(x_train, y_train.ravel())\n",
    "    valid_sets = lgb.Dataset(x_val, y_val.ravel())\n",
    "\n",
    "    model = lgb.train(params, lgbm_dataset, 100000, valid_sets=valid_sets, early_stopping_rounds=10)\n",
    "    y_pred = model.predict(x_val)\n",
    "    \n",
    "    loss = log_loss(y_val, y_pred)\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    acc = accuracy_score(y_val, (y_pred > 0.5).astype(int))\n",
    "#     model.save_model(file_path + \"-%04d-%.5f-%.5f.h5\" % (model.best_iteration, loss, acc),\n",
    "#                      num_iteration=model.best_iteration)\n",
    "    print(\"val loss : %.5f\" % loss)\n",
    "    print(\"auc score : %.5f\" % auc)\n",
    "    print(\"accuracy score : %.5f\" % acc)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_etrain = get_ember_feature(x_train)\n",
    "x_eval = get_ember_feature(x_val)\n",
    "x_etest = get_ember_feature(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.611326\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.545228\n",
      "[3]\tvalid_0's binary_logloss: 0.489771\n",
      "[4]\tvalid_0's binary_logloss: 0.442264\n",
      "[5]\tvalid_0's binary_logloss: 0.401525\n",
      "[6]\tvalid_0's binary_logloss: 0.365412\n",
      "[7]\tvalid_0's binary_logloss: 0.333953\n",
      "[8]\tvalid_0's binary_logloss: 0.307177\n",
      "[9]\tvalid_0's binary_logloss: 0.282782\n",
      "[10]\tvalid_0's binary_logloss: 0.261964\n",
      "[11]\tvalid_0's binary_logloss: 0.242456\n",
      "[12]\tvalid_0's binary_logloss: 0.225985\n",
      "[13]\tvalid_0's binary_logloss: 0.210507\n",
      "[14]\tvalid_0's binary_logloss: 0.197181\n",
      "[15]\tvalid_0's binary_logloss: 0.184133\n",
      "[16]\tvalid_0's binary_logloss: 0.173379\n",
      "[17]\tvalid_0's binary_logloss: 0.162612\n",
      "[18]\tvalid_0's binary_logloss: 0.153024\n",
      "[19]\tvalid_0's binary_logloss: 0.144421\n",
      "[20]\tvalid_0's binary_logloss: 0.136783\n",
      "[21]\tvalid_0's binary_logloss: 0.129512\n",
      "[22]\tvalid_0's binary_logloss: 0.122847\n",
      "[23]\tvalid_0's binary_logloss: 0.11697\n",
      "[24]\tvalid_0's binary_logloss: 0.111408\n",
      "[25]\tvalid_0's binary_logloss: 0.10621\n",
      "[26]\tvalid_0's binary_logloss: 0.101785\n",
      "[27]\tvalid_0's binary_logloss: 0.0978702\n",
      "[28]\tvalid_0's binary_logloss: 0.0943082\n",
      "[29]\tvalid_0's binary_logloss: 0.0908742\n",
      "[30]\tvalid_0's binary_logloss: 0.0875062\n",
      "[31]\tvalid_0's binary_logloss: 0.0842581\n",
      "[32]\tvalid_0's binary_logloss: 0.0813345\n",
      "[33]\tvalid_0's binary_logloss: 0.0785564\n",
      "[34]\tvalid_0's binary_logloss: 0.0757417\n",
      "[35]\tvalid_0's binary_logloss: 0.0736189\n",
      "[36]\tvalid_0's binary_logloss: 0.0713243\n",
      "[37]\tvalid_0's binary_logloss: 0.0695658\n",
      "[38]\tvalid_0's binary_logloss: 0.0675484\n",
      "[39]\tvalid_0's binary_logloss: 0.0655049\n",
      "[40]\tvalid_0's binary_logloss: 0.0637837\n",
      "[41]\tvalid_0's binary_logloss: 0.0622457\n",
      "[42]\tvalid_0's binary_logloss: 0.0610754\n",
      "[43]\tvalid_0's binary_logloss: 0.0595208\n",
      "[44]\tvalid_0's binary_logloss: 0.0582801\n",
      "[45]\tvalid_0's binary_logloss: 0.0570944\n",
      "[46]\tvalid_0's binary_logloss: 0.0558353\n",
      "[47]\tvalid_0's binary_logloss: 0.0545678\n",
      "[48]\tvalid_0's binary_logloss: 0.0537404\n",
      "[49]\tvalid_0's binary_logloss: 0.052865\n",
      "[50]\tvalid_0's binary_logloss: 0.0518487\n",
      "[51]\tvalid_0's binary_logloss: 0.0510396\n",
      "[52]\tvalid_0's binary_logloss: 0.0501935\n",
      "[53]\tvalid_0's binary_logloss: 0.0494862\n",
      "[54]\tvalid_0's binary_logloss: 0.0487308\n",
      "[55]\tvalid_0's binary_logloss: 0.0480972\n",
      "[56]\tvalid_0's binary_logloss: 0.0474816\n",
      "[57]\tvalid_0's binary_logloss: 0.0468\n",
      "[58]\tvalid_0's binary_logloss: 0.0460087\n",
      "[59]\tvalid_0's binary_logloss: 0.0452601\n",
      "[60]\tvalid_0's binary_logloss: 0.0446442\n",
      "[61]\tvalid_0's binary_logloss: 0.0442127\n",
      "[62]\tvalid_0's binary_logloss: 0.043606\n",
      "[63]\tvalid_0's binary_logloss: 0.0430202\n",
      "[64]\tvalid_0's binary_logloss: 0.0423671\n",
      "[65]\tvalid_0's binary_logloss: 0.0419502\n",
      "[66]\tvalid_0's binary_logloss: 0.0414354\n",
      "[67]\tvalid_0's binary_logloss: 0.0410606\n",
      "[68]\tvalid_0's binary_logloss: 0.040638\n",
      "[69]\tvalid_0's binary_logloss: 0.0401741\n",
      "[70]\tvalid_0's binary_logloss: 0.0397554\n",
      "[71]\tvalid_0's binary_logloss: 0.0393226\n",
      "[72]\tvalid_0's binary_logloss: 0.0390176\n",
      "[73]\tvalid_0's binary_logloss: 0.0387204\n",
      "[74]\tvalid_0's binary_logloss: 0.0384028\n",
      "[75]\tvalid_0's binary_logloss: 0.038103\n",
      "[76]\tvalid_0's binary_logloss: 0.0378178\n",
      "[77]\tvalid_0's binary_logloss: 0.0373598\n",
      "[78]\tvalid_0's binary_logloss: 0.037082\n",
      "[79]\tvalid_0's binary_logloss: 0.0368426\n",
      "[80]\tvalid_0's binary_logloss: 0.0365849\n",
      "[81]\tvalid_0's binary_logloss: 0.0362546\n",
      "[82]\tvalid_0's binary_logloss: 0.0360442\n",
      "[83]\tvalid_0's binary_logloss: 0.0357222\n",
      "[84]\tvalid_0's binary_logloss: 0.0355772\n",
      "[85]\tvalid_0's binary_logloss: 0.0352957\n",
      "[86]\tvalid_0's binary_logloss: 0.0350579\n",
      "[87]\tvalid_0's binary_logloss: 0.0348432\n",
      "[88]\tvalid_0's binary_logloss: 0.0346579\n",
      "[89]\tvalid_0's binary_logloss: 0.0344955\n",
      "[90]\tvalid_0's binary_logloss: 0.0343564\n",
      "[91]\tvalid_0's binary_logloss: 0.0340591\n",
      "[92]\tvalid_0's binary_logloss: 0.0338277\n",
      "[93]\tvalid_0's binary_logloss: 0.0337169\n",
      "[94]\tvalid_0's binary_logloss: 0.0335094\n",
      "[95]\tvalid_0's binary_logloss: 0.0333152\n",
      "[96]\tvalid_0's binary_logloss: 0.0330881\n",
      "[97]\tvalid_0's binary_logloss: 0.0328582\n",
      "[98]\tvalid_0's binary_logloss: 0.0326366\n",
      "[99]\tvalid_0's binary_logloss: 0.0325197\n",
      "[100]\tvalid_0's binary_logloss: 0.0323313\n",
      "[101]\tvalid_0's binary_logloss: 0.0321632\n",
      "[102]\tvalid_0's binary_logloss: 0.0320494\n",
      "[103]\tvalid_0's binary_logloss: 0.031625\n",
      "[104]\tvalid_0's binary_logloss: 0.0315137\n",
      "[105]\tvalid_0's binary_logloss: 0.0314573\n",
      "[106]\tvalid_0's binary_logloss: 0.0313378\n",
      "[107]\tvalid_0's binary_logloss: 0.03116\n",
      "[108]\tvalid_0's binary_logloss: 0.0310437\n",
      "[109]\tvalid_0's binary_logloss: 0.0309416\n",
      "[110]\tvalid_0's binary_logloss: 0.030826\n",
      "[111]\tvalid_0's binary_logloss: 0.0306843\n",
      "[112]\tvalid_0's binary_logloss: 0.0305788\n",
      "[113]\tvalid_0's binary_logloss: 0.030506\n",
      "[114]\tvalid_0's binary_logloss: 0.0303308\n",
      "[115]\tvalid_0's binary_logloss: 0.0301757\n",
      "[116]\tvalid_0's binary_logloss: 0.0299839\n",
      "[117]\tvalid_0's binary_logloss: 0.0298965\n",
      "[118]\tvalid_0's binary_logloss: 0.0296973\n",
      "[119]\tvalid_0's binary_logloss: 0.0295442\n",
      "[120]\tvalid_0's binary_logloss: 0.0294785\n",
      "[121]\tvalid_0's binary_logloss: 0.0293153\n",
      "[122]\tvalid_0's binary_logloss: 0.0292542\n",
      "[123]\tvalid_0's binary_logloss: 0.0291152\n",
      "[124]\tvalid_0's binary_logloss: 0.0290396\n",
      "[125]\tvalid_0's binary_logloss: 0.0288805\n",
      "[126]\tvalid_0's binary_logloss: 0.0288249\n",
      "[127]\tvalid_0's binary_logloss: 0.0287477\n",
      "[128]\tvalid_0's binary_logloss: 0.0286703\n",
      "[129]\tvalid_0's binary_logloss: 0.0285479\n",
      "[130]\tvalid_0's binary_logloss: 0.0284466\n",
      "[131]\tvalid_0's binary_logloss: 0.0283071\n",
      "[132]\tvalid_0's binary_logloss: 0.0282203\n",
      "[133]\tvalid_0's binary_logloss: 0.0281029\n",
      "[134]\tvalid_0's binary_logloss: 0.0280631\n",
      "[135]\tvalid_0's binary_logloss: 0.0279883\n",
      "[136]\tvalid_0's binary_logloss: 0.0279224\n",
      "[137]\tvalid_0's binary_logloss: 0.0278624\n",
      "[138]\tvalid_0's binary_logloss: 0.02782\n",
      "[139]\tvalid_0's binary_logloss: 0.0277193\n",
      "[140]\tvalid_0's binary_logloss: 0.0276659\n",
      "[141]\tvalid_0's binary_logloss: 0.0275456\n",
      "[142]\tvalid_0's binary_logloss: 0.0274284\n",
      "[143]\tvalid_0's binary_logloss: 0.0273499\n",
      "[144]\tvalid_0's binary_logloss: 0.0272856\n",
      "[145]\tvalid_0's binary_logloss: 0.0272008\n",
      "[146]\tvalid_0's binary_logloss: 0.0271629\n",
      "[147]\tvalid_0's binary_logloss: 0.0271018\n",
      "[148]\tvalid_0's binary_logloss: 0.027021\n",
      "[149]\tvalid_0's binary_logloss: 0.0270082\n",
      "[150]\tvalid_0's binary_logloss: 0.0269539\n",
      "[151]\tvalid_0's binary_logloss: 0.0268551\n",
      "[152]\tvalid_0's binary_logloss: 0.0267446\n",
      "[153]\tvalid_0's binary_logloss: 0.0267158\n",
      "[154]\tvalid_0's binary_logloss: 0.0266468\n",
      "[155]\tvalid_0's binary_logloss: 0.0265748\n",
      "[156]\tvalid_0's binary_logloss: 0.0264596\n",
      "[157]\tvalid_0's binary_logloss: 0.0263709\n",
      "[158]\tvalid_0's binary_logloss: 0.0262826\n",
      "[159]\tvalid_0's binary_logloss: 0.0262309\n",
      "[160]\tvalid_0's binary_logloss: 0.026108\n",
      "[161]\tvalid_0's binary_logloss: 0.0260296\n",
      "[162]\tvalid_0's binary_logloss: 0.0259599\n",
      "[163]\tvalid_0's binary_logloss: 0.0259632\n",
      "[164]\tvalid_0's binary_logloss: 0.0259403\n",
      "[165]\tvalid_0's binary_logloss: 0.025865\n",
      "[166]\tvalid_0's binary_logloss: 0.0257537\n",
      "[167]\tvalid_0's binary_logloss: 0.02576\n",
      "[168]\tvalid_0's binary_logloss: 0.0256498\n",
      "[169]\tvalid_0's binary_logloss: 0.025618\n",
      "[170]\tvalid_0's binary_logloss: 0.0256264\n",
      "[171]\tvalid_0's binary_logloss: 0.025616\n",
      "[172]\tvalid_0's binary_logloss: 0.0255362\n",
      "[173]\tvalid_0's binary_logloss: 0.025459\n",
      "[174]\tvalid_0's binary_logloss: 0.0254989\n",
      "[175]\tvalid_0's binary_logloss: 0.0254476\n",
      "[176]\tvalid_0's binary_logloss: 0.0253725\n",
      "[177]\tvalid_0's binary_logloss: 0.0253383\n",
      "[178]\tvalid_0's binary_logloss: 0.0252738\n",
      "[179]\tvalid_0's binary_logloss: 0.025217\n",
      "[180]\tvalid_0's binary_logloss: 0.0251493\n",
      "[181]\tvalid_0's binary_logloss: 0.0251306\n",
      "[182]\tvalid_0's binary_logloss: 0.0250761\n",
      "[183]\tvalid_0's binary_logloss: 0.0250153\n",
      "[184]\tvalid_0's binary_logloss: 0.0249157\n",
      "[185]\tvalid_0's binary_logloss: 0.0248523\n",
      "[186]\tvalid_0's binary_logloss: 0.0248007\n",
      "[187]\tvalid_0's binary_logloss: 0.0247294\n",
      "[188]\tvalid_0's binary_logloss: 0.0247282\n",
      "[189]\tvalid_0's binary_logloss: 0.0247591\n",
      "[190]\tvalid_0's binary_logloss: 0.0246821\n",
      "[191]\tvalid_0's binary_logloss: 0.0245998\n",
      "[192]\tvalid_0's binary_logloss: 0.0245182\n",
      "[193]\tvalid_0's binary_logloss: 0.0244765\n",
      "[194]\tvalid_0's binary_logloss: 0.0244643\n",
      "[195]\tvalid_0's binary_logloss: 0.0243929\n",
      "[196]\tvalid_0's binary_logloss: 0.0243309\n",
      "[197]\tvalid_0's binary_logloss: 0.0242963\n",
      "[198]\tvalid_0's binary_logloss: 0.0243131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199]\tvalid_0's binary_logloss: 0.0243037\n",
      "[200]\tvalid_0's binary_logloss: 0.0242221\n",
      "[201]\tvalid_0's binary_logloss: 0.0242247\n",
      "[202]\tvalid_0's binary_logloss: 0.0241727\n",
      "[203]\tvalid_0's binary_logloss: 0.0240803\n",
      "[204]\tvalid_0's binary_logloss: 0.024034\n",
      "[205]\tvalid_0's binary_logloss: 0.023964\n",
      "[206]\tvalid_0's binary_logloss: 0.0238902\n",
      "[207]\tvalid_0's binary_logloss: 0.023861\n",
      "[208]\tvalid_0's binary_logloss: 0.023862\n",
      "[209]\tvalid_0's binary_logloss: 0.0238614\n",
      "[210]\tvalid_0's binary_logloss: 0.0237772\n",
      "[211]\tvalid_0's binary_logloss: 0.0237241\n",
      "[212]\tvalid_0's binary_logloss: 0.0237328\n",
      "[213]\tvalid_0's binary_logloss: 0.0237472\n",
      "[214]\tvalid_0's binary_logloss: 0.0237391\n",
      "[215]\tvalid_0's binary_logloss: 0.0237735\n",
      "[216]\tvalid_0's binary_logloss: 0.0237247\n",
      "[217]\tvalid_0's binary_logloss: 0.0237179\n",
      "[218]\tvalid_0's binary_logloss: 0.0236478\n",
      "[219]\tvalid_0's binary_logloss: 0.0236075\n",
      "[220]\tvalid_0's binary_logloss: 0.0235903\n",
      "[221]\tvalid_0's binary_logloss: 0.0236002\n",
      "[222]\tvalid_0's binary_logloss: 0.023534\n",
      "[223]\tvalid_0's binary_logloss: 0.0235234\n",
      "[224]\tvalid_0's binary_logloss: 0.0235066\n",
      "[225]\tvalid_0's binary_logloss: 0.0234483\n",
      "[226]\tvalid_0's binary_logloss: 0.0234263\n",
      "[227]\tvalid_0's binary_logloss: 0.0233816\n",
      "[228]\tvalid_0's binary_logloss: 0.0233449\n",
      "[229]\tvalid_0's binary_logloss: 0.0233133\n",
      "[230]\tvalid_0's binary_logloss: 0.0233116\n",
      "[231]\tvalid_0's binary_logloss: 0.0233111\n",
      "[232]\tvalid_0's binary_logloss: 0.0233166\n",
      "[233]\tvalid_0's binary_logloss: 0.023285\n",
      "[234]\tvalid_0's binary_logloss: 0.0231909\n",
      "[235]\tvalid_0's binary_logloss: 0.0231827\n",
      "[236]\tvalid_0's binary_logloss: 0.0231756\n",
      "[237]\tvalid_0's binary_logloss: 0.0231662\n",
      "[238]\tvalid_0's binary_logloss: 0.0231558\n",
      "[239]\tvalid_0's binary_logloss: 0.0231066\n",
      "[240]\tvalid_0's binary_logloss: 0.0230844\n",
      "[241]\tvalid_0's binary_logloss: 0.0230287\n",
      "[242]\tvalid_0's binary_logloss: 0.0229814\n",
      "[243]\tvalid_0's binary_logloss: 0.022932\n",
      "[244]\tvalid_0's binary_logloss: 0.022953\n",
      "[245]\tvalid_0's binary_logloss: 0.0229488\n",
      "[246]\tvalid_0's binary_logloss: 0.0229307\n",
      "[247]\tvalid_0's binary_logloss: 0.022926\n",
      "[248]\tvalid_0's binary_logloss: 0.022938\n",
      "[249]\tvalid_0's binary_logloss: 0.0229298\n",
      "[250]\tvalid_0's binary_logloss: 0.0229629\n",
      "[251]\tvalid_0's binary_logloss: 0.0229119\n",
      "[252]\tvalid_0's binary_logloss: 0.0228988\n",
      "[253]\tvalid_0's binary_logloss: 0.0228819\n",
      "[254]\tvalid_0's binary_logloss: 0.0228408\n",
      "[255]\tvalid_0's binary_logloss: 0.0228335\n",
      "[256]\tvalid_0's binary_logloss: 0.0228457\n",
      "[257]\tvalid_0's binary_logloss: 0.0228303\n",
      "[258]\tvalid_0's binary_logloss: 0.0227652\n",
      "[259]\tvalid_0's binary_logloss: 0.0227636\n",
      "[260]\tvalid_0's binary_logloss: 0.0227509\n",
      "[261]\tvalid_0's binary_logloss: 0.0227525\n",
      "[262]\tvalid_0's binary_logloss: 0.0227145\n",
      "[263]\tvalid_0's binary_logloss: 0.0226908\n",
      "[264]\tvalid_0's binary_logloss: 0.0227037\n",
      "[265]\tvalid_0's binary_logloss: 0.022667\n",
      "[266]\tvalid_0's binary_logloss: 0.0226623\n",
      "[267]\tvalid_0's binary_logloss: 0.0226649\n",
      "[268]\tvalid_0's binary_logloss: 0.0226685\n",
      "[269]\tvalid_0's binary_logloss: 0.0226458\n",
      "[270]\tvalid_0's binary_logloss: 0.0226269\n",
      "[271]\tvalid_0's binary_logloss: 0.0226186\n",
      "[272]\tvalid_0's binary_logloss: 0.0225657\n",
      "[273]\tvalid_0's binary_logloss: 0.0225765\n",
      "[274]\tvalid_0's binary_logloss: 0.022586\n",
      "[275]\tvalid_0's binary_logloss: 0.0226381\n",
      "[276]\tvalid_0's binary_logloss: 0.0226611\n",
      "[277]\tvalid_0's binary_logloss: 0.0226474\n",
      "[278]\tvalid_0's binary_logloss: 0.0226361\n",
      "[279]\tvalid_0's binary_logloss: 0.0226435\n",
      "[280]\tvalid_0's binary_logloss: 0.0226293\n",
      "[281]\tvalid_0's binary_logloss: 0.0226119\n",
      "[282]\tvalid_0's binary_logloss: 0.0225935\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's binary_logloss: 0.0225657\n",
      "val loss : 0.02257\n",
      "auc score : 0.99966\n",
      "accuracy score : 0.99120\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model = get_model(x_etrain, y_train, x_eval, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_model(y_pred, test_y):\n",
    "    \n",
    "    loss = log_loss(test_y, y_pred)\n",
    "    auc = roc_auc_score(test_y, y_pred)\n",
    "    acc = accuracy_score(test_y, (y_pred > 0.5).astype(int))\n",
    "    print(\"loss : %.5f\" % loss)\n",
    "    print(\"auc score : %.5f\" % auc)\n",
    "    print(\"accuracy score : %.5f\" % acc)\n",
    "\n",
    "    fp_np_index = np.where(test_y == 0)\n",
    "    fp_np = y_pred[fp_np_index].shape[0]\n",
    "    thre_index = int(np.ceil(fp_np - fp_np * 0.001))\n",
    "\n",
    "    sorted_pred_prob = np.sort(y_pred[fp_np_index], axis=0)\n",
    "    thre = sorted_pred_prob[thre_index]\n",
    "    if thre == 1:\n",
    "        thre = max(sorted_pred_prob[np.where(sorted_pred_prob != 1)])\n",
    "\n",
    "    y_pred_prob = np.vstack((y_pred.transpose(), (1 - y_pred).transpose())).transpose()\n",
    "    y_pred_prob[:, 1] = thre\n",
    "    y_pred_label = np.argmin(y_pred_prob, axis=-1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(test_y, y_pred_label).ravel()\n",
    "    fp_rate = fp / (fp + tn)\n",
    "    recall_rate = tp / (tp + fn)\n",
    "\n",
    "    print(\"thre: %.10f\"%  thre)\n",
    "    print(\"fp:  %.10f\"%  fp_rate)\n",
    "    print(\"recall:  %.10f\"%  recall_rate)\n",
    "    \n",
    "    return auc, loss, recall_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.24118\n",
      "auc score : 0.98498\n",
      "accuracy score : 0.96377\n",
      "thre: 0.9999957052\n",
      "fp:  0.0009623157\n",
      "recall:  0.0825126263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9849844963890804, 0.24117966536573404, 0.08251262626262626)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = model.predict(x_etest)\n",
    "y_pred_e = np.zeros((len(y_p), 1))\n",
    "for i in range(len(y_p)):\n",
    "    y_pred_e[i, 0] = y_p[i]\n",
    "\n",
    "estimate_model(y_pred_e, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, list_IDs, datasets, labels, batch_size=32, dim=8192, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.datasets = datasets\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, self.dim), dtype=float)\n",
    "        y = np.zeros(self.batch_size, dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            base_path = \"/ssd/2017/{0}/{1}{2}\"\n",
    "            item = self.datasets.loc[ID]\n",
    "            file_path = base_path.format(item[\"mw_file_directory\"], item[\"mw_file_hash\"], item[\"mw_file_size\"])\n",
    "            in_file = open(file_path, 'rb')\n",
    "            in_file.seek(item['pointerto_raw_data'])\n",
    "            bytes_data = [int(single_byte) for single_byte in in_file.read(item['virtual_size'])]\n",
    "            X[i, 0:len(bytes_data)] = bytes_data\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras import Input\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Dense, Embedding, Conv1D, Multiply, GlobalMaxPooling1D, Dropout\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TMalConv(object):\n",
    "    \"\"\"\n",
    "    train of mal conv\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.max_len = max_length\n",
    "        self.history = None\n",
    "        self.model = None\n",
    "        self.p_md5 = None\n",
    "        self.time = time.time()\n",
    "        self.summary = {\n",
    "            'time':time.time(),\n",
    "            'batch_size': 32,\n",
    "            'epochs': 64,\n",
    "            'g_c_filter': 128,\n",
    "            'g_c_kernel_size': 500,\n",
    "            'g_c_stride': 500,\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        \n",
    "    def get_p(self, key):\n",
    "        \"\"\"\n",
    "        get the parameter from the summary\n",
    "        :param key:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.summary[key]\n",
    "\n",
    "    def gate_cnn(self, gate_cnn_input):\n",
    "        \"\"\"\n",
    "        construct a gated cnn by the specific kernel size\n",
    "        :param gate_cnn_input:\n",
    "        :param kernel_size:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        conv1_out = Conv1D(self.get_p(\"g_c_filter\"), self.get_p(\"g_c_kernel_size\"), strides=self.get_p(\"g_c_stride\"))(\n",
    "            gate_cnn_input)\n",
    "        conv2_out = Conv1D(self.get_p(\"g_c_filter\"), self.get_p(\"g_c_kernel_size\"), strides=self.get_p(\"g_c_stride\"),\n",
    "                           activation=\"sigmoid\")(gate_cnn_input)\n",
    "        merged = Multiply()([conv1_out, conv2_out])\n",
    "        gate_cnn_output = GlobalMaxPooling1D()(merged)\n",
    "        return gate_cnn_output\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        get a model\n",
    "        :param max_len:\n",
    "        :param kernel_sizes:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        net_input = Input(shape=(self.max_len,))\n",
    "\n",
    "        embedding_out = Embedding(256, 8, input_length=self.max_len)(net_input)\n",
    "        merged = self.gate_cnn(embedding_out)\n",
    "\n",
    "        dense_out = Dense(128)(merged)\n",
    "        \n",
    "        net_output = Dense(1, activation='sigmoid')(dense_out)\n",
    "\n",
    "        model = keras.models.Model(inputs=net_input, outputs=net_output)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        batch_size = self.get_p(\"batch_size\")\n",
    "        epochs = self.get_p(\"epochs\")\n",
    "\n",
    "        self.model = self.get_model()\n",
    "\n",
    "        print('Length of the train: ', len(x_train))\n",
    "        print('Length of the validation: ', len(x_val))\n",
    "        \n",
    "#         tensor_board = TensorBoard(log_dir='./logs/', batch_size=batch_size)\n",
    "        file_path = \"/home/zhaoqi/BaseTrain/models/\"+ str(self.time) +\"-{epoch:04d}-{val_loss:.5f}-{val_acc:.5f}.h5\"\n",
    "        early_stopping = EarlyStopping(\"val_loss\", patience=3, verbose=0, mode='auto')\n",
    "        check_point = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "        callbacks_list = [check_point, early_stopping]\n",
    "\n",
    "        # Generators\n",
    "        training_generator = DataGenerator(range(len(x_train)), x_train, y_train, batch_size, self.max_len)\n",
    "        validation_generator = DataGenerator(range(len(x_val)), x_val, y_val, batch_size, self.max_len)\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "        self.model.fit_generator(generator=training_generator,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 use_multiprocessing=True,\n",
    "                                 epochs=epochs,\n",
    "                                 workers=6,\n",
    "                                 callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train:  93077\n",
      "Length of the validation:  10342\n",
      "Epoch 1/64\n",
      "2908/2908 [==============================] - 952s 327ms/step - loss: 0.1620 - acc: 0.9376 - val_loss: 0.1357 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13568, saving model to /home/zhaoqi/BaseTrain/models/1531997458.8325162-0001-0.13568-0.94998.h5\n",
      "Epoch 2/64\n",
      "2908/2908 [==============================] - 1190s 409ms/step - loss: 0.0944 - acc: 0.9706 - val_loss: 0.1249 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13568 to 0.12492, saving model to /home/zhaoqi/BaseTrain/models/1531997458.8325162-0002-0.12492-0.95414.h5\n",
      "Epoch 3/64\n",
      "2908/2908 [==============================] - 1500s 516ms/step - loss: 0.0651 - acc: 0.9851 - val_loss: 0.1314 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12492\n",
      "Epoch 4/64\n",
      "2908/2908 [==============================] - 1499s 515ms/step - loss: 0.0571 - acc: 0.9884 - val_loss: 0.1428 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12492\n",
      "Epoch 5/64\n",
      "2908/2908 [==============================] - 1459s 502ms/step - loss: 0.0517 - acc: 0.9899 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12492\n"
     ]
    }
   ],
   "source": [
    "t_instance = TMalConv()\n",
    "t_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2118/2118 [==============================] - 867s 409ms/step\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/home/zhaoqi/BaseTrain/models/'\n",
    "f_name = '1531997458.8325162-0002-0.12492-0.95414.h5'\n",
    "c_model = load_model(model_dir + f_name)\n",
    "\n",
    "test_generator = DataGenerator(range(len(x_test)), x_test, y_test, 32, max_length, False)\n",
    "y_pred = c_model.predict_generator(generator=test_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.26196\n",
      "auc score : 0.97068\n",
      "accuracy score : 0.93539\n",
      "thre: 0.9997478127\n",
      "fp:  0.0009626121\n",
      "recall:  0.0410509031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9706777008840716, 0.26196404833713366, 0.041050903119868636)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_model(y_pred, y_test[0:len(y_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Malconv and Ember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2908/2908 [==============================] - 1287s 443ms/step\n",
      "323/323 [==============================] - 152s 470ms/step\n",
      "2118/2118 [==============================] - 934s 441ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model_f = Model(c_model.input, c_model.layers[-2].output)\n",
    "\n",
    "train_generator = DataGenerator(range(len(x_train)), x_train, y_train, 32, max_length, False)\n",
    "malcon_train_x = model_f.predict_generator(generator=train_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)\n",
    "\n",
    "val_generator = DataGenerator(range(len(x_val)), x_val, y_val, 32, max_length, False)\n",
    "malcon_val_x = model_f.predict_generator(generator=val_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)\n",
    "\n",
    "test_generator = DataGenerator(range(len(x_test)), x_test, y_test, 32, max_length, False)\n",
    "malcon_test_x = model_f.predict_generator(generator=test_generator, max_queue_size=10, workers=6, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.608134\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.53956\n",
      "[3]\tvalid_0's binary_logloss: 0.482521\n",
      "[4]\tvalid_0's binary_logloss: 0.434895\n",
      "[5]\tvalid_0's binary_logloss: 0.394731\n",
      "[6]\tvalid_0's binary_logloss: 0.360475\n",
      "[7]\tvalid_0's binary_logloss: 0.330977\n",
      "[8]\tvalid_0's binary_logloss: 0.305727\n",
      "[9]\tvalid_0's binary_logloss: 0.283994\n",
      "[10]\tvalid_0's binary_logloss: 0.265143\n",
      "[11]\tvalid_0's binary_logloss: 0.248652\n",
      "[12]\tvalid_0's binary_logloss: 0.234477\n",
      "[13]\tvalid_0's binary_logloss: 0.222189\n",
      "[14]\tvalid_0's binary_logloss: 0.211543\n",
      "[15]\tvalid_0's binary_logloss: 0.202204\n",
      "[16]\tvalid_0's binary_logloss: 0.194232\n",
      "[17]\tvalid_0's binary_logloss: 0.187318\n",
      "[18]\tvalid_0's binary_logloss: 0.181133\n",
      "[19]\tvalid_0's binary_logloss: 0.175902\n",
      "[20]\tvalid_0's binary_logloss: 0.171292\n",
      "[21]\tvalid_0's binary_logloss: 0.167301\n",
      "[22]\tvalid_0's binary_logloss: 0.163888\n",
      "[23]\tvalid_0's binary_logloss: 0.161171\n",
      "[24]\tvalid_0's binary_logloss: 0.158777\n",
      "[25]\tvalid_0's binary_logloss: 0.156799\n",
      "[26]\tvalid_0's binary_logloss: 0.155234\n",
      "[27]\tvalid_0's binary_logloss: 0.153842\n",
      "[28]\tvalid_0's binary_logloss: 0.152814\n",
      "[29]\tvalid_0's binary_logloss: 0.152006\n",
      "[30]\tvalid_0's binary_logloss: 0.151304\n",
      "[31]\tvalid_0's binary_logloss: 0.150643\n",
      "[32]\tvalid_0's binary_logloss: 0.150263\n",
      "[33]\tvalid_0's binary_logloss: 0.149795\n",
      "[34]\tvalid_0's binary_logloss: 0.149566\n",
      "[35]\tvalid_0's binary_logloss: 0.14941\n",
      "[36]\tvalid_0's binary_logloss: 0.149341\n",
      "[37]\tvalid_0's binary_logloss: 0.149575\n",
      "[38]\tvalid_0's binary_logloss: 0.149557\n",
      "[39]\tvalid_0's binary_logloss: 0.149733\n",
      "[40]\tvalid_0's binary_logloss: 0.150072\n",
      "[41]\tvalid_0's binary_logloss: 0.150285\n",
      "[42]\tvalid_0's binary_logloss: 0.150488\n",
      "[43]\tvalid_0's binary_logloss: 0.150767\n",
      "[44]\tvalid_0's binary_logloss: 0.151061\n",
      "[45]\tvalid_0's binary_logloss: 0.151293\n",
      "[46]\tvalid_0's binary_logloss: 0.151708\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.149341\n",
      "val loss : 0.14934\n",
      "auc score : 0.98924\n",
      "accuracy score : 0.95462\n"
     ]
    }
   ],
   "source": [
    "model_m = get_model(malcon_train_x, y_train[0:len(malcon_train_x)], malcon_val_x, y_val[0:len(malcon_val_x)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.24731\n",
      "auc score : 0.97065\n",
      "accuracy score : 0.92909\n",
      "thre: 0.9863750093\n",
      "fp:  0.0000770090\n",
      "recall:  0.0003157762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.970649811030129, 0.24731460953844853, 0.0003157761778451434)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = model_m.predict(malcon_test_x)\n",
    "y_pred = np.zeros((len(y_p), 1))\n",
    "for i in range(len(y_p)):\n",
    "    y_pred[i, 0] = y_p[i]\n",
    "\n",
    "estimate_model(y_pred, y_test[0:len(malcon_test_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_feature(m_data, e_data):\n",
    "    num = len(m_data)\n",
    "    m_x = np.zeros((num, 128+2351), dtype=float)\n",
    "    \n",
    "    for index in range(num):\n",
    "        m_x[index, 0:128] = m_data[index]\n",
    "        m_x[index, 128:128+2351] = e_data[index]  \n",
    "    return m_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.605535\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.534004\n",
      "[3]\tvalid_0's binary_logloss: 0.474748\n",
      "[4]\tvalid_0's binary_logloss: 0.424647\n",
      "[5]\tvalid_0's binary_logloss: 0.382659\n",
      "[6]\tvalid_0's binary_logloss: 0.346437\n",
      "[7]\tvalid_0's binary_logloss: 0.315354\n",
      "[8]\tvalid_0's binary_logloss: 0.287779\n",
      "[9]\tvalid_0's binary_logloss: 0.263552\n",
      "[10]\tvalid_0's binary_logloss: 0.242721\n",
      "[11]\tvalid_0's binary_logloss: 0.224152\n",
      "[12]\tvalid_0's binary_logloss: 0.2076\n",
      "[13]\tvalid_0's binary_logloss: 0.193193\n",
      "[14]\tvalid_0's binary_logloss: 0.180624\n",
      "[15]\tvalid_0's binary_logloss: 0.169606\n",
      "[16]\tvalid_0's binary_logloss: 0.159523\n",
      "[17]\tvalid_0's binary_logloss: 0.150378\n",
      "[18]\tvalid_0's binary_logloss: 0.142689\n",
      "[19]\tvalid_0's binary_logloss: 0.135555\n",
      "[20]\tvalid_0's binary_logloss: 0.129519\n",
      "[21]\tvalid_0's binary_logloss: 0.124052\n",
      "[22]\tvalid_0's binary_logloss: 0.119223\n",
      "[23]\tvalid_0's binary_logloss: 0.115013\n",
      "[24]\tvalid_0's binary_logloss: 0.110862\n",
      "[25]\tvalid_0's binary_logloss: 0.107365\n",
      "[26]\tvalid_0's binary_logloss: 0.103964\n",
      "[27]\tvalid_0's binary_logloss: 0.1011\n",
      "[28]\tvalid_0's binary_logloss: 0.0982013\n",
      "[29]\tvalid_0's binary_logloss: 0.0957272\n",
      "[30]\tvalid_0's binary_logloss: 0.0935218\n",
      "[31]\tvalid_0's binary_logloss: 0.0917581\n",
      "[32]\tvalid_0's binary_logloss: 0.0898755\n",
      "[33]\tvalid_0's binary_logloss: 0.0883942\n",
      "[34]\tvalid_0's binary_logloss: 0.0872638\n",
      "[35]\tvalid_0's binary_logloss: 0.0861606\n",
      "[36]\tvalid_0's binary_logloss: 0.0850493\n",
      "[37]\tvalid_0's binary_logloss: 0.0840489\n",
      "[38]\tvalid_0's binary_logloss: 0.0824845\n",
      "[39]\tvalid_0's binary_logloss: 0.0817264\n",
      "[40]\tvalid_0's binary_logloss: 0.0811873\n",
      "[41]\tvalid_0's binary_logloss: 0.0810001\n",
      "[42]\tvalid_0's binary_logloss: 0.0801309\n",
      "[43]\tvalid_0's binary_logloss: 0.0800317\n",
      "[44]\tvalid_0's binary_logloss: 0.0793194\n",
      "[45]\tvalid_0's binary_logloss: 0.0788984\n",
      "[46]\tvalid_0's binary_logloss: 0.0783926\n",
      "[47]\tvalid_0's binary_logloss: 0.0779815\n",
      "[48]\tvalid_0's binary_logloss: 0.077337\n",
      "[49]\tvalid_0's binary_logloss: 0.076994\n",
      "[50]\tvalid_0's binary_logloss: 0.076684\n",
      "[51]\tvalid_0's binary_logloss: 0.0765583\n",
      "[52]\tvalid_0's binary_logloss: 0.0761868\n",
      "[53]\tvalid_0's binary_logloss: 0.0759864\n",
      "[54]\tvalid_0's binary_logloss: 0.0759573\n",
      "[55]\tvalid_0's binary_logloss: 0.075281\n",
      "[56]\tvalid_0's binary_logloss: 0.0752364\n",
      "[57]\tvalid_0's binary_logloss: 0.0747442\n",
      "[58]\tvalid_0's binary_logloss: 0.0740123\n",
      "[59]\tvalid_0's binary_logloss: 0.0736043\n",
      "[60]\tvalid_0's binary_logloss: 0.0737605\n",
      "[61]\tvalid_0's binary_logloss: 0.0738506\n",
      "[62]\tvalid_0's binary_logloss: 0.0732838\n",
      "[63]\tvalid_0's binary_logloss: 0.0733051\n",
      "[64]\tvalid_0's binary_logloss: 0.0731648\n",
      "[65]\tvalid_0's binary_logloss: 0.0730232\n",
      "[66]\tvalid_0's binary_logloss: 0.0727007\n",
      "[67]\tvalid_0's binary_logloss: 0.0727247\n",
      "[68]\tvalid_0's binary_logloss: 0.0727716\n",
      "[69]\tvalid_0's binary_logloss: 0.072629\n",
      "[70]\tvalid_0's binary_logloss: 0.0728451\n",
      "[71]\tvalid_0's binary_logloss: 0.0725934\n",
      "[72]\tvalid_0's binary_logloss: 0.0721017\n",
      "[73]\tvalid_0's binary_logloss: 0.0722674\n",
      "[74]\tvalid_0's binary_logloss: 0.0724654\n",
      "[75]\tvalid_0's binary_logloss: 0.0726933\n",
      "[76]\tvalid_0's binary_logloss: 0.0727606\n",
      "[77]\tvalid_0's binary_logloss: 0.0728353\n",
      "[78]\tvalid_0's binary_logloss: 0.0727447\n",
      "[79]\tvalid_0's binary_logloss: 0.0728339\n",
      "[80]\tvalid_0's binary_logloss: 0.0730837\n",
      "[81]\tvalid_0's binary_logloss: 0.0726974\n",
      "[82]\tvalid_0's binary_logloss: 0.0727675\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.0721017\n",
      "val loss : 0.07210\n",
      "auc score : 0.99773\n",
      "accuracy score : 0.97581\n"
     ]
    }
   ],
   "source": [
    "merge_train_x = merge_feature(malcon_train_x, x_etrain)\n",
    "merge_val_x = merge_feature(malcon_val_x, x_eval)\n",
    "merge_test_x = merge_feature(malcon_test_x, x_etest)\n",
    "\n",
    "model_m = get_model(merge_train_x, y_train[0:len(merge_train_x)], merge_val_x, y_val[0:len(merge_val_x)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.25190\n",
      "auc score : 0.98125\n",
      "accuracy score : 0.94895\n",
      "thre: 0.9995773224\n",
      "fp:  0.0000000000\n",
      "recall:  0.0000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9812466612240963, 0.251895966677737, 0.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = model_m.predict(merge_test_x)\n",
    "y_pred = np.zeros((len(y_p), 1))\n",
    "for i in range(len(y_p)):\n",
    "    y_pred[i, 0] = y_p[i]\n",
    "\n",
    "estimate_model(y_pred, y_test[0:len(merge_test_x)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
